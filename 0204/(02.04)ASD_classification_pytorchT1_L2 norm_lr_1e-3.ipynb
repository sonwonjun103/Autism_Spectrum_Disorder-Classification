{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d840d79",
   "metadata": {},
   "source": [
    "# 0. Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25fca3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "import random\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import pydicom as dcm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import *\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67760899",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG={'Image_Size':256,\n",
    "    'EPOCHS':100,\n",
    "    'BATCH_SIZE':2,\n",
    "    'Learning_rate':1e-3,\n",
    "    'beta_1':0.9,\n",
    "    'beta_2':0.99,\n",
    "    'eps':0.00000001,\n",
    "     'weight_decay':0.000001,\n",
    "    'Channel_size':8,\n",
    "    'SEED':42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "537e2e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966f6805",
   "metadata": {},
   "source": [
    "# 1. Check Gpu Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b998d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device  : cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=\"cuda\"\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "    \n",
    "print(f\"device  : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b2b53fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the graphic card : NVIDIA GeForce RTX 4090\n",
      "Number of gpu : 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Name of the graphic card : {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Number of gpu : {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0414e0",
   "metadata": {},
   "source": [
    "### Make Trash can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dbdafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e9860c",
   "metadata": {},
   "source": [
    "### Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79339166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=True\n",
    "\n",
    "seed_everything(CFG['SEED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a585cf",
   "metadata": {},
   "source": [
    "# 2. Get Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b02dbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASD Image Data :  203\n",
      "ASD+TC Image Data :  261\n"
     ]
    }
   ],
   "source": [
    "path_asd='C:\\\\Users\\\\PC00\\\\Desktop\\\\ASD_data\\\\ASD\\\\'\n",
    "path_control='C:\\\\Users\\\\PC00\\\\Desktop\\\\ASD_data\\\\CONTROL\\\\'\n",
    "\n",
    "asd_p=os.listdir(path_asd)\n",
    "control_p=os.listdir(path_control)\n",
    "\n",
    "MRI_image=['SPGR_P']\n",
    "all_image_path=[]\n",
    "\n",
    "for name in asd_p:\n",
    "    path=''\n",
    "    for image in MRI_image:\n",
    "        path=path_asd+name+'\\\\'+'aNew'+'\\\\'\n",
    "        path=path+image+'\\\\'\n",
    "        if 'Test' in path or '3564' in path or '3395' in path or '3278' in path or '3466' in path or '3624' in path or '3603' in path or '3632' in path or '3663' in path:\n",
    "            pass\n",
    "        else:\n",
    "            all_image_path.append(path)\n",
    "print(\"ASD Image Data : \" , len(all_image_path)) \n",
    "for name in control_p:\n",
    "    path=''\n",
    "    for image in MRI_image:\n",
    "        path=path_control+name+'\\\\'+'aNew'+'\\\\'\n",
    "        path=path+image+'\\\\'\n",
    "        if 'Test' in path or '3564' in path or '3395' in path or '3278' in path or '3466' in path or '3624' in path or '3603' in path or '3632' in path or '3663' in path:\n",
    "            pass\n",
    "        else:\n",
    "            all_image_path.append(path)\n",
    "        \n",
    "print(\"ASD+TC Image Data : \" ,len(all_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a06da8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1101_ASY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1111_KJW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1113_LJH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1321_KSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1332_LJM\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1542_KYL\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1543_BYS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1563_CYS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1659_YHS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1692_CMK\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1694_LDW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1712_SHJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1727_SYS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1734_PJW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1736_KSJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1746_YDK\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1751_CYS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1787_CWJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1812_PMJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1820_PSY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1835_SHM\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1856_CJW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1888_ASY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1901_WHS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\1914_KMS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2026_CJW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2038_KMS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2054_LKH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2071_LWH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2105_CHW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2126_SES\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2157_WJY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2239_KHJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2247_KBY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2261_KKB\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2262_ASY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2288_CWS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2304_HLA\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2322_KSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2333_CSW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2356_KHJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2383_PSY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2442_SJW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2478_CHK\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2524_KSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2540_PDK\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2600_HJH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2610_PHY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2626_CYW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2654_PYN\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2659_SJW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2711_CYR\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2719_HKY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2733_PSB\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2768_LKM\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2780_KHJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2784_KMS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2793_LDY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2811_HTS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2819_KSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2853_LSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2886_LSM\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2898_JHS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2899_LHN\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2912_PKL\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2922_JJW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2932_LSC\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2936_SYW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\2983_KMH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3009_PCH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3011_LSW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3031_SEH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3044_LJH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3070_CYY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3127_KDH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3207_KHK\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3341_SCW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3347_KTW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3401_MJH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3420_CSY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3488_KSW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3516_LSY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3519_SMK\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3522_HSO\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3563_LYS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3565_LYR\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3608_KBJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3628_YSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3635_KSM\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3662_KYB\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3672_YSB\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3685_SYH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3722_SNRB\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3723_KRH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3744_BSW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\3951_CAY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\398_LJH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4021_SSY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4026_KBM\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4029_LSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4038_JKH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4043_KYR\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4044_SYJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4047_JKH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4067_PSW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4082_PJW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4088_LCY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4099_JHW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4109_UDM\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4134_SMJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4140_LHM\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4154_KYS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4156_LDK\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4157_KSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4184_PHM\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4195_NYJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4204_SYJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4214_PJS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4224_YIS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4235_LSJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4242_LHY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4259_PSY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4270_CAI\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\427_LSA\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4280_PJH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4283_CYW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4302_CHE\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4312_KYB\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4323_KYC\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4355_YJH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4372_KSJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\438KMJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4396_KDW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4464_LHJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4478_5_SJH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4543_KJI\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4586_JYW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4600_LJH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4618_KKH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4655_HJA\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4681_PSH_DL\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4696_LSY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4704_SOY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4740_KDH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4753_KHK_DL\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4773_DY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4787_ODE\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4804_KHN_DL\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4806_KWK_DL\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4827_SYJ_DL\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4887_JBY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4890_LSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4907_HJW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4916_SJW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4925_KJW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4951_KHJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4954_LYJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\495_KDY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4994_KHM\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\4997_KMH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\502_CJW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\510_CSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\5129_LHS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\5139_PJS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\5141_JHJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\5169_LDO\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\5249_KDH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\5253_USJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\5274_OJH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\5282_OYR\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\5296_KTY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\5334_HSM\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\5338_KMJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\5345_KTH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\5347_KEH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\537_PMJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\544_KSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\571_KJY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\592_LHJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\622_HYJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\633_CSW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\652_LSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\653_LJW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\780_OSL\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\821_LSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\838_KHW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\858_PSY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\903_LJH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\955_JSM\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\972_HHJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\s4-05_PDJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\s4-07_JYC\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\s4-107_PJS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\s4-111_PCW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\s4-13_YSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\s4-174_alexander\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\s4-175_MKH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\s4-234_JJH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\s4-238_KSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\s4-240_KDK\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\s4-73_JWK\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\s4-97_PHJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\s6-14_PHW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\1040_PSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\1084_CJS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\1665_LJY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\1825_HSJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\1928_HDE\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\1982_LCH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\2027_PCY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\2039_CMK\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\2235_LSJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\2513_KYW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\2742_OYK\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\2909_KDE\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\2917_JHJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\3002_KKW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\3243_KKE\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\3356_AIH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\3390_PSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\3415_PCA\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\3472_MJY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\3520_PYK\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\3525_BJY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\3650_OYK\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\3706_LYJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\3834_HJH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\3864_PSJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\3972_LMS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\3979_LSJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\3993_PSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\425_KAY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\4329_KMJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\4440_SYS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\4623_RJH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\4629_PDAN\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\4702_KHR\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\4803_MTM\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\5190_JSA\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\536_KMS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\569_KJW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\5776_LSM\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\5789_JRO\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\5863_KYJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\5933_MHMD\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\5945_PEW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\638_SSA\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\716_JYW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\733_WJA\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\736_SYT\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\779_CHJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\876_KBJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\s4-102\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\s4-266\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\s4-282\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\s4-29\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\s4-31\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\s4-326\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\s4-67\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\s4-98\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\s6-78_SHJ\\aNew\\SPGR_P\\\n"
     ]
    }
   ],
   "source": [
    "for info in all_image_path:\n",
    "    print(info)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f975e5de",
   "metadata": {},
   "source": [
    "# 3. Make Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9d39617",
   "metadata": {},
   "outputs": [],
   "source": [
    "label=np.array([1]*203+[0]*(261-203), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2b291c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n"
     ]
    }
   ],
   "source": [
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b0e885e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "n=np.unique(label, axis=0)\n",
    "n=n.shape[0]\n",
    "\n",
    "label=np.eye(n)[label]\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2921819",
   "metadata": {},
   "source": [
    "# 4. Divide Data path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a16464e",
   "metadata": {},
   "source": [
    "Fix Test set for 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e016c33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ASD Image Data :  10\n",
      "Test ASD+TC Image Data :  20\n"
     ]
    }
   ],
   "source": [
    "test_asd='C:\\\\Users\\\\PC00\\\\Desktop\\\\ASD_data\\\\ASD\\\\Test\\\\'\n",
    "test_control='C:\\\\Users\\\\PC00\\\\Desktop\\\\ASD_data\\\\CONTROL\\\\Test\\\\'\n",
    "\n",
    "test_asd_p=os.listdir(test_asd)\n",
    "test_control_p=os.listdir(test_control)\n",
    "\n",
    "#MRI_image=['SPGR_P','MAGIC_T2']\n",
    "MRI_image=['SPGR_P']\n",
    "test_image_path=[]\n",
    "\n",
    "for name in test_asd_p:\n",
    "    path=''\n",
    "    for image in MRI_image:\n",
    "        path=test_asd+name+'\\\\'+'aNew'+'\\\\'\n",
    "        path=path+image+'\\\\'\n",
    "        test_image_path.append(path)\n",
    "print(\"Test ASD Image Data : \" , len(test_image_path)) \n",
    "for name in test_control_p:\n",
    "    path=''\n",
    "    for image in MRI_image:\n",
    "        path=test_control+name+'\\\\'+'aNew'+'\\\\'\n",
    "        path=path+image+'\\\\'\n",
    "        test_image_path.append(path)\n",
    "        \n",
    "print(\"Test ASD+TC Image Data : \" ,len(test_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7c1ffdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\Test\\4837_KDK_DL\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\Test\\4838_KKW_DL\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\Test\\4839_PRK_DL\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\Test\\4859_PJH_DL\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\Test\\4881_JWJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\Test\\5010_PHS\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\Test\\5023_PDK\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\Test\\5036_HKM\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\Test\\5102_KMJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\ASD\\Test\\5115_HW\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\Test\\4371_SHJ\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\Test\\4582_MSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\Test\\4808_KTH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\Test\\4917_JSO\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\Test\\4931_LSY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\Test\\5158_KJH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\Test\\5301_KKY\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\Test\\5341_KSM\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\Test\\5533_BSH\\aNew\\SPGR_P\\\n",
      "C:\\Users\\PC00\\Desktop\\ASD_data\\CONTROL\\Test\\5660_KSY\\aNew\\SPGR_P\\\n"
     ]
    }
   ],
   "source": [
    "for p in test_image_path:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9d80d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label=np.array([1]*10+[0]*10, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "265267ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0830195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "n=np.unique(test_label, axis=0)\n",
    "n=n.shape[0]\n",
    "\n",
    "test_label=np.eye(n)[test_label]\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab26f242",
   "metadata": {},
   "source": [
    "Train : Val = 0.8 : 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bf4142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path, val_path, train_label, val_label=train_test_split(all_image_path, label, test_size=0.3, random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b0f216a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182 79 182 79\n"
     ]
    }
   ],
   "source": [
    "print(len(train_path), len(val_path), len(train_label), len(val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13eebd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ASD :  142\n",
      "Train TC :  40\n"
     ]
    }
   ],
   "source": [
    "train_asd=0\n",
    "train_tc=0\n",
    "for path in train_path:\n",
    "    if 'CONTROL' in path:\n",
    "        train_tc+=1\n",
    "    \n",
    "train_asd=len(train_path)-train_tc      \n",
    "print(\"Train ASD : \", train_asd)\n",
    "print(\"Train TC : \", train_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86c28232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val ASD :  61\n",
      "Val TC :  18\n"
     ]
    }
   ],
   "source": [
    "val_asd=0\n",
    "val_tc=0\n",
    "for path in val_path:\n",
    "    if 'CONTROL' in path:\n",
    "        val_tc+=1\n",
    "    \n",
    "val_asd=len(val_path)-val_tc      \n",
    "print(\"Val ASD : \", val_asd)\n",
    "print(\"Val TC : \", val_tc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9567dd",
   "metadata": {},
   "source": [
    "# 5. Transform and augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f3b23f",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4801d5",
   "metadata": {},
   "source": [
    "### Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "966bfa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_image=[[0]*256]*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "792d50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T1_resize(img_volume, plus_image):\n",
    "    #(256, 256, 188)\n",
    "    \n",
    "    want_channel=188\n",
    "    original_channel=img_volume.shape[0]\n",
    "    difference=abs(want_channel-original_channel)\n",
    "  \n",
    "    #차이가 짝수이면\n",
    "    if difference==0:\n",
    "        return img_volume\n",
    "    else:\n",
    "        img_volume=list(img_volume)\n",
    "        if difference%2==0:\n",
    "            #front & behind\n",
    "            for _ in range(difference//2):\n",
    "                img_volume.insert(0, plus_image)\n",
    "                img_volume.insert(len(img_volume), plus_image)\n",
    "                \n",
    "            return np.array(img_volume)\n",
    "        \n",
    "        else:\n",
    "            #front\n",
    "            for _ in range(difference//2):\n",
    "                img_volume.insert(0, plus_image)\n",
    "            #behind    \n",
    "            for _ in range(difference//2+1):\n",
    "                img_volume.insert(len(img_volume), plus_image)\n",
    "                \n",
    "            return np.array(img_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bfd3127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T2_resize(img_volume, plus_image):\n",
    "    #(256, 256, 34)\n",
    "    \n",
    "    want_channel=34\n",
    "    original_channel=img_volume.shape[0]\n",
    "    difference=abs(want_channel-original_channel)\n",
    "  \n",
    "    if difference==0:\n",
    "        return img_volume\n",
    "    else:\n",
    "        img_volume=list(img_volume)\n",
    "        #차이가 짝수이면\n",
    "        if difference%2==0:\n",
    "            #front & behind\n",
    "            for _ in range(difference//2):\n",
    "                img_volume.insert(0, plus_image)\n",
    "                img_volume.insert(len(img_volume), plus_image)\n",
    "                \n",
    "            return np.array(img_volume)\n",
    "        \n",
    "        else:\n",
    "            #front\n",
    "            for _ in range(difference//2):\n",
    "                img_volume.insert(0, plus_image)\n",
    "            #behind    \n",
    "            for _ in range(difference//2+1):\n",
    "                img_volume.insert(len(img_volume), plus_image)\n",
    "                \n",
    "            return np.array(img_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dcc4a9",
   "metadata": {},
   "source": [
    "### cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e183399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T1_crop(img_volume):\n",
    "    area=(25, 45, 215, 210)\n",
    "    img_crop_volume=[]\n",
    "    for i in range(img_volume.shape[0]):\n",
    "        img=img_volume[i]\n",
    "    \n",
    "        img=Image.fromarray(np.uint16(img))\n",
    "\n",
    "        img=img.crop(area)\n",
    "        \n",
    "        img=np.array(img)\n",
    "        img=list(img)\n",
    "        img_crop_volume.append(img)\n",
    "  \n",
    "    img_crop_volume=np.array(img_crop_volume)\n",
    "    return img_crop_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63055ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T2_crop(img_volume):\n",
    "    area=(40, 20, 225, 225)\n",
    "    img_crop_volume=[]\n",
    "    for i in range(img_volume.shape[0]):\n",
    "        img=img_volume[i]\n",
    "    \n",
    "        img=Image.fromarray(np.uint16(img))\n",
    "\n",
    "        img=img.crop(area)\n",
    "        \n",
    "        img=np.array(img)\n",
    "        img=list(img)\n",
    "        img_crop_volume.append(img)\n",
    "  \n",
    "    img_crop_volume=np.array(img_crop_volume)\n",
    "    return img_crop_volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5658c23b",
   "metadata": {},
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4600863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxScaler3D(MinMaxScaler):\n",
    "    def fit_transform(self, X,y=None):\n",
    "        x=np.reshape(X, newshape=(X.shape[0]*X.shape[1], X.shape[2]))\n",
    "        return np.reshape(super().fit_transform(x, y=y), newshape=X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3edb114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler3D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ac00a8",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9990be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60173399",
   "metadata": {},
   "source": [
    "# 6. Get Image from data path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce9d65f",
   "metadata": {},
   "source": [
    "Convert to numpy (dicom -> numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0e6f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numpy(sitk_volume, size):\n",
    "    \"\"\"convert sitk image to numpy volume\"\"\"\n",
    "    img_volume = sitk.GetArrayFromImage(sitk_volume)\n",
    "    img_volume = img_volume.transpose(2,1,0)\n",
    "    #print(img_volume.shape)\n",
    "    if img_volume.shape[0]!=CFG['Image_Size']:\n",
    "        img_volume = cv2.resize(img_volume, dsize=(CFG['Image_Size'], CFG['Image_Size']))\n",
    "    \n",
    "    #img_volume = img_volume.transpose(1,2,0)\n",
    "    \n",
    "    return img_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50a5c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(path):\n",
    "    reader=sitk.ImageSeriesReader()\n",
    "    dicom_names=reader.GetGDCMSeriesFileNames(path)\n",
    "    \n",
    "    #print(\"Number of Series : \", len(dicom_names))\n",
    "    \n",
    "    reader.SetFileNames(dicom_names)\n",
    "    \n",
    "    image=reader.Execute()\n",
    "    size=image.GetSize()\n",
    "    #print(\"Original size of series : \", size[0], size[1], size[2])\n",
    "    img_volume=convert_to_numpy(image, size)\n",
    "    \n",
    "    img_volume=img_volume.transpose(2,1,0)\n",
    "    \n",
    "    if 'SPGR_P' in path:\n",
    "        img_volume=T1_resize(img_volume, pad_image)\n",
    "        img_volume=T1_crop(img_volume)\n",
    "    elif 'MAGIC_T2' in path:\n",
    "        img_volume=T2_resize(img_volume, pad_image)\n",
    "        img_volume=T2_crop(img_volume)\n",
    "    #print(\"Convert size of series : \", img_volume.shape[0], img_volume.shape[1], img_volume.shape[2])\n",
    "    img_volume = scaler.fit_transform(img_volume)\n",
    "    return img_volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab8ffcf",
   "metadata": {},
   "source": [
    "# 7. CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d84e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#T1+T2\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, path,labels, transforms=None):\n",
    "        self.path=path\n",
    "        self.labels=torch.from_numpy(labels)\n",
    "        self.transforms=transforms\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        #add label\n",
    "        state=self.labels[idx]\n",
    "        state=state.cuda()\n",
    "        \n",
    "        image=get_image(self.path[idx])\n",
    "        image=np.array(image, dtype=np.int64)\n",
    "        image=torch.from_numpy(image)\n",
    "        \n",
    "        image=torch.reshape(image,(1,image.shape[0], image.shape[1], image.shape[2]))\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        image=image.cuda()\n",
    "        \n",
    "        return image, state\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "160f4097",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=CustomDataset(train_path, train_label)\n",
    "val_data=CustomDataset(val_path, val_label)\n",
    "\n",
    "test_data=CustomDataset(test_image_path, test_label) # 나중에 augmentation할 때 적용 하면 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06f88af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n"
     ]
    }
   ],
   "source": [
    "n=random.randint(0,len(train_label))\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39e32150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 188, 165, 190])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.__getitem__(n)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7693685",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(train_data, batch_size=CFG['BATCH_SIZE'],shuffle=True)\n",
    "validation_dataloader=DataLoader(val_data, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "test_dataloader=DataLoader(test_data, batch_size=CFG['BATCH_SIZE'],shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1d8ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels=next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e100a00",
   "metadata": {},
   "source": [
    "# 8. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90d4ee7",
   "metadata": {},
   "source": [
    "## 3D CSResNet Model = CS Block + 3D ResNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fd62b2",
   "metadata": {},
   "source": [
    "## CS Block\n",
    "Channel block + spatial block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63e85709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg','max']):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_channels=gate_channels\n",
    "        self.mlp=nn.Sequential(\n",
    "                        Flatten(),\n",
    "                        nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
    "        )\n",
    "        self.pool_types=pool_types\n",
    "        \n",
    "    def forward(self, x):\n",
    "        channel_att_sum=None\n",
    "        #print(\"Input of Channel gate shape : \", x.size(0), x.size(1), x.size(2), x.size(3)) # 8 64 17 64 64\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type=='avg':\n",
    "                avg_pool = F.avg_pool3d( x, (x.size(2), x.size(3), x.size(4)), stride=(x.size(2), x.size(3), x.size(4)))\n",
    "                channel_att_raw = self.mlp( avg_pool )\n",
    "            elif pool_type=='max':\n",
    "                max_pool = F.max_pool3d( x, (x.size(2), x.size(3), x.size(4)), stride=(x.size(2), x.size(3), x.size(4)))\n",
    "                channel_att_raw = self.mlp( max_pool )\n",
    "            elif pool_type=='lp':\n",
    "                lp_pool = F.lp_pool3d( x, (x.size(2), x.size(3), x.size(4)), stride=(x.size(2), x.size(3), x.size(4)))\n",
    "                channel_att_raw = self.mlp( lp_pool )\n",
    "                \n",
    "            if channel_att_sum is None:\n",
    "                channel_att_sum=channel_att_raw\n",
    "            else:\n",
    "                channel_att_sum=channel_att_sum+channel_att_raw\n",
    "                \n",
    "        scale = F.sigmoid(channel_att_sum).unsqueeze(2).unsqueeze(3).unsqueeze(4).expand_as(x)\n",
    "        return x*scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21fb2c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        self.conv = nn.Conv3d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm3d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e3fd79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
    "\n",
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialGate, self).__init__()\n",
    "        kernel_size=7\n",
    "        self.compress=ChannelPool()\n",
    "        self.spatial=BasicConv(2,1, kernel_size, stride=1, padding=(kernel_size-1)//2, relu=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_compress=self.compress(x)\n",
    "        x_out=self.spatial(x_compress)\n",
    "        scale=F.sigmoid(x_out) #broadcasting\n",
    "        return x*scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96ac86ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg','max'], no_spatial=False):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ChannelGate=ChannelGate(gate_channels, reduction_ratio, pool_types)\n",
    "        self.no_spatial=no_spatial\n",
    "        if not no_spatial:\n",
    "            self.SpatialGate=SpatialGate()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x_out=self.ChannelGate(x)\n",
    "        if not self.no_spatial:\n",
    "            x_out=self.SpatialGate(x_out)\n",
    "            \n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82410553",
   "metadata": {},
   "source": [
    "## 3D ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a0f23bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inplanes():\n",
    "    return [64, 128, 256, 512]\n",
    "\n",
    "def conv3x3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv3d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=3,\n",
    "                     stride=stride,\n",
    "                     padding=1,\n",
    "                     bias=False)\n",
    "\n",
    "def conv1x1x1(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv3d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=1,\n",
    "                     stride=stride,\n",
    "                     bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None, CBAM_use=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = conv3x3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dropout=nn.Dropout(0.2)\n",
    "        \n",
    "        if CBAM:\n",
    "            self.cbam=CBAM(planes, 16)\n",
    "        else:\n",
    "            self.cbam=None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "            \n",
    "        if not self.cbam is None:\n",
    "            out=self.cbam(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5bdca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, \n",
    "                 block, #Basicblock\n",
    "                 layers, #[2,2,2,2]\n",
    "                 block_inplanes, #[64, 128, 256, 512]\n",
    "                 in_channels, #1\n",
    "                 out_channels, #64\n",
    "                 shortcut_type='B',\n",
    "                 att_type=None,\n",
    "                 stride=2, \n",
    "                 n_classes=2): #1, 64\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_planes=block_inplanes[0]\n",
    "        self.no_max_pool=False\n",
    "\n",
    "        self.conv1=nn.Conv3d(in_channels, self.in_planes, kernel_size=(7,7,7), stride=(1,2,2), padding=(7//2,3,3), bias=False)\n",
    "        self.bn1=nn.BatchNorm3d(out_channels)\n",
    "        self.relu=nn.ReLU(inplace=True) #? -> 기존의 데이터를 연산의 결괏값으로 대체하는 것\n",
    "        self.maxpool=nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1=self._make_layer(block, block_inplanes[0], layers[0], shortcut_type)\n",
    "        self.layer2=self._make_layer(block, block_inplanes[1], layers[1], shortcut_type, stride=2)\n",
    "        self.layer3=self._make_layer(block, block_inplanes[2], layers[2], shortcut_type, stride=2)\n",
    "        self.layer4=self._make_layer(block, block_inplanes[3], layers[3], shortcut_type, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1,1,1))\n",
    "        self.fc=nn.Linear(block_inplanes[3]*block.expansion, n_classes)\n",
    "        self.sigmoid=torch.nn.Sigmoid()\n",
    "        self.log_softmax=torch.nn.LogSoftmax()\n",
    "        self.softmax=torch.nn.Softmax()\n",
    "        \n",
    "        if att_type=='BAM':\n",
    "            self.bam1=BAM(64*block.expansion)\n",
    "            self.bam2=BAM(128*block.expansion)\n",
    "            self.bam3=BAM(256*block.expansion)\n",
    "        else:\n",
    "            self.bam1, self.bam2, self.bam3=None, None, None\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') # He initialization\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight, 1) # 초기값  설정\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n",
    "        downsample=None\n",
    "        if stride!=1 or self.in_planes != planes*block.expansion:\n",
    "            if shortcut_type=='A':\n",
    "                downsample=partial(self._dwonsample_basic_block, planes=planes * block.expansion, stride=stride)\n",
    "            else:\n",
    "                downsample=nn.Sequential(\n",
    "                    conv1x1x1(self.in_planes, planes*block.expansion, stride),\n",
    "                    nn.BatchNorm3d(planes*block.expansion),\n",
    "                )\n",
    "\n",
    "        layers=[]\n",
    "        layers.append(\n",
    "            block(in_planes=self.in_planes, planes=planes, stride=stride, downsample=downsample, CBAM_use=True),\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.in_planes=planes*block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.in_planes, planes, CBAM_use=True))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.bn1(x)\n",
    "        x=self.relu(x)\n",
    "        if not self.no_max_pool:\n",
    "            x=self.maxpool(x)\n",
    "\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "\n",
    "        x=self.avgpool(x)\n",
    "        \n",
    "        x=x.view(x.size(0), -1)\n",
    "        #print(f\"x shape : {x.shape}\\{x}\")\n",
    "        x=self.fc(x)\n",
    "        #print(f\"x shape : {x.shape}\\{x}\")\n",
    "        #x=self.sigmoid(x)\n",
    "        x=self.softmax(x)\n",
    "        #print(f\"x shape : {x.shape}\\{x}\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a352131",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ResNet18(BasicBlock, [2,2,2,2], get_inplanes(), 1, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0a25408",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e357022b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet18(\n",
       "  (conv1): Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=64, out_features=4, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=4, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "            (bn): BatchNorm3d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=64, out_features=4, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=4, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "            (bn): BatchNorm3d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=8, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "            (bn): BatchNorm3d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=8, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "            (bn): BatchNorm3d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "            (bn): BatchNorm3d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "            (bn): BatchNorm3d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=512, out_features=32, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=32, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "            (bn): BatchNorm3d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=512, out_features=32, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=32, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "            (bn): BatchNorm3d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (log_softmax): LogSoftmax(dim=None)\n",
       "  (softmax): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e718d933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 33,255,610 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02846fc",
   "metadata": {},
   "source": [
    "# 9. Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2501a605",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim()>2:\n",
    "            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1,1)\n",
    "\n",
    "        logpt = F.log_softmax(input)\n",
    "        print(type(logpt), logpt.shape)\n",
    "        print(logpt)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0,target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d80e3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss().to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters(), \n",
    "                           lr=CFG['Learning_rate'], \n",
    "                           betas=(CFG['beta_1'], CFG['beta_2']), \n",
    "                           eps=CFG['eps'], \n",
    "                           weight_decay=CFG['weight_decay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fab24d",
   "metadata": {},
   "source": [
    "# 10. EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c409ea1",
   "metadata": {},
   "source": [
    "### EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bde72a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baece51f",
   "metadata": {},
   "source": [
    "### ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "160f756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode, factor, patience, threshold, cooldown, eps\n",
    "LR_condition={'mode':'min',\n",
    "            'factor' : 0.5,\n",
    "            'patience' : 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a12a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler=optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                               mode=LR_condition['mode'], \n",
    "                                               factor=LR_condition['factor'], \n",
    "                                               patience=LR_condition['patience'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a94d5",
   "metadata": {},
   "source": [
    "# 11. KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85de6028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3a894f0",
   "metadata": {},
   "source": [
    "# 12. Train & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6aae7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, scheduler):\n",
    "    \n",
    "    size=len(dataloader.dataset)\n",
    "    print(\"데이터 사이즈 : \", size)\n",
    "    \n",
    "    train_loss, correct=0,0\n",
    "    #scheduler.step()\n",
    "    model.train()\n",
    "    \n",
    "    #autograd engine(gradient를 계산해주는 context)을 비활성화 시켜 필요한 메모리를 줄여주고 연산속도 증가\n",
    "    \n",
    "    for batch, (X,y) in (enumerate((dataloader))):\n",
    "        X=Variable(X.to(device).float())\n",
    "        y=Variable(y.to(device).float())\n",
    "        pred=model(X)\n",
    "        loss=loss_fn(pred,y)\n",
    "        #print(f\"pred {pred}\")\n",
    "    \n",
    "        #L2 norm\n",
    "        L2_lambda=0.0001\n",
    "        L2_norm=sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "        \n",
    "        loss=loss+L2_lambda/2*L2_norm\n",
    "        \n",
    "        train_loss+=loss.item()\n",
    "        correct+=(pred.argmax(1)==y.argmax(1)).type(torch.float).sum().item()\n",
    " \n",
    "        #역전파\n",
    "        optimizer.zero_grad() #gradient를 0으로 초기화\n",
    "        loss.requires_grad_(True)\n",
    "        loss.backward() #비용 함수를 미분하여 gradient 계산\n",
    "        optimizer.step() #update weight and bias\n",
    "        \n",
    "        if batch%10==0:\n",
    "            loss, current=loss.item(), batch*len(X)\n",
    "            print(f\"Batch {batch} loss : {loss:>7f} [{current:>5d}/{size:>5d}]\")  \n",
    "        \n",
    "    train_loss/=size\n",
    "    correct/=size\n",
    "    \n",
    "    print(f\"Train\\n Accuracy : {(100*correct):>0.1f}%, Avg Loss : {train_loss:>8f}\\n\")\n",
    "    return train_loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f12a0564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loop(dataloader, model, loss_fn, scheduler):\n",
    "    size=len(dataloader.dataset)\n",
    "    \n",
    "    num_batches=len(dataloader)\n",
    "    val_loss, correct=0,0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            X=Variable(X.to(device).float())\n",
    "            y=Variable(y.to(device).float())\n",
    "            pred=model(X)\n",
    "            \n",
    "            loss=loss_fn(pred,y)\n",
    "            \n",
    "            #L2 norm\n",
    "            L2_lambda=0.0001\n",
    "            L2_norm=sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "            loss=loss+L2_lambda/2*L2_norm\n",
    "            \n",
    "            val_loss+=loss.item()\n",
    "            \n",
    "            #scheduler.step(val_loss)\n",
    "            \n",
    "            correct+=(pred.argmax(1)==y.argmax(1)).type(torch.float).sum().item()\n",
    "            \n",
    "    val_loss/=num_batches\n",
    "    correct/=size\n",
    "    \n",
    "    print(f\"Validation\\n Accuracy : {(100*correct):>0.1f}%, Avg Loss : {val_loss:>8f}\\n\")\n",
    "    return val_loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d10b6e07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 1.344950 [    0/  182]\n",
      "Batch 10 loss : 0.986474 [   20/  182]\n",
      "Batch 20 loss : 1.187826 [   40/  182]\n",
      "Batch 30 loss : 1.377484 [   60/  182]\n",
      "Batch 40 loss : 1.335331 [   80/  182]\n",
      "Batch 50 loss : 0.804835 [  100/  182]\n",
      "Batch 60 loss : 0.765544 [  120/  182]\n",
      "Batch 70 loss : 1.246328 [  140/  182]\n",
      "Batch 80 loss : 0.711252 [  160/  182]\n",
      "Batch 90 loss : 1.271528 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.525701\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.936448\n",
      "\n",
      "Epcoh time : 6.0분 13.557599782943726 초\n",
      "Epoch 1 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 1.680863 [    0/  182]\n",
      "Batch 10 loss : 0.668650 [   20/  182]\n",
      "Batch 20 loss : 1.150098 [   40/  182]\n",
      "Batch 30 loss : 0.644373 [   60/  182]\n",
      "Batch 40 loss : 1.620512 [   80/  182]\n",
      "Batch 50 loss : 1.091567 [  100/  182]\n",
      "Batch 60 loss : 0.597942 [  120/  182]\n",
      "Batch 70 loss : 0.609299 [  140/  182]\n",
      "Batch 80 loss : 0.581640 [  160/  182]\n",
      "Batch 90 loss : 0.565509 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.421357\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.789974\n",
      "\n",
      "Epcoh time : 4.0분 55.59165024757385 초\n",
      "Epoch 2 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.564592 [    0/  182]\n",
      "Batch 10 loss : 1.057178 [   20/  182]\n",
      "Batch 20 loss : 0.546688 [   40/  182]\n",
      "Batch 30 loss : 0.538610 [   60/  182]\n",
      "Batch 40 loss : 1.030528 [   80/  182]\n",
      "Batch 50 loss : 1.024900 [  100/  182]\n",
      "Batch 60 loss : 1.016378 [  120/  182]\n",
      "Batch 70 loss : 0.510523 [  140/  182]\n",
      "Batch 80 loss : 0.504559 [  160/  182]\n",
      "Batch 90 loss : 0.498365 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.374301\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.722706\n",
      "\n",
      "Epcoh time : 4.0분 49.432865858078 초\n",
      "Epoch 3 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.996363 [    0/  182]\n",
      "Batch 10 loss : 0.493211 [   20/  182]\n",
      "Batch 20 loss : 0.986158 [   40/  182]\n",
      "Batch 30 loss : 0.980485 [   60/  182]\n",
      "Batch 40 loss : 0.977404 [   80/  182]\n",
      "Batch 50 loss : 0.472649 [  100/  182]\n",
      "Batch 60 loss : 0.466849 [  120/  182]\n",
      "Batch 70 loss : 0.962629 [  140/  182]\n",
      "Batch 80 loss : 0.956690 [  160/  182]\n",
      "Batch 90 loss : 0.456792 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.347382\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.682595\n",
      "\n",
      "Epcoh time : 4.0분 59.339051961898804 초\n",
      "Epoch 4 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.955221 [    0/  182]\n",
      "Batch 10 loss : 0.452826 [   20/  182]\n",
      "Batch 20 loss : 0.446540 [   40/  182]\n",
      "Batch 30 loss : 0.441385 [   60/  182]\n",
      "Batch 40 loss : 0.936763 [   80/  182]\n",
      "Batch 50 loss : 0.933070 [  100/  182]\n",
      "Batch 60 loss : 0.429521 [  120/  182]\n",
      "Batch 70 loss : 0.925556 [  140/  182]\n",
      "Batch 80 loss : 0.422075 [  160/  182]\n",
      "Batch 90 loss : 0.418829 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.327904\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.643464\n",
      "\n",
      "Epcoh time : 4.0분 54.66447639465332 초\n",
      "Epoch 5 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.418594 [    0/  182]\n",
      "Batch 10 loss : 0.928579 [   20/  182]\n",
      "Batch 20 loss : 0.431220 [   40/  182]\n",
      "Batch 30 loss : 0.419826 [   60/  182]\n",
      "Batch 40 loss : 0.412139 [   80/  182]\n",
      "Batch 50 loss : 0.406695 [  100/  182]\n",
      "Batch 60 loss : 0.402436 [  120/  182]\n",
      "Batch 70 loss : 0.398894 [  140/  182]\n",
      "Batch 80 loss : 0.895640 [  160/  182]\n",
      "Batch 90 loss : 0.393605 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.315518\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.618270\n",
      "\n",
      "Epcoh time : 4.0분 58.98343849182129 초\n",
      "Epoch 6 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.393420 [    0/  182]\n",
      "Batch 10 loss : 0.890183 [   20/  182]\n",
      "Batch 20 loss : 0.387558 [   40/  182]\n",
      "Batch 30 loss : 0.394320 [   60/  182]\n",
      "Batch 40 loss : 0.890106 [   80/  182]\n",
      "Batch 50 loss : 0.385346 [  100/  182]\n",
      "Batch 60 loss : 0.879366 [  120/  182]\n",
      "Batch 70 loss : 0.877931 [  140/  182]\n",
      "Batch 80 loss : 0.375077 [  160/  182]\n",
      "Batch 90 loss : 0.372159 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.302146\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.596961\n",
      "\n",
      "Epcoh time : 4.0분 54.452394247055054 초\n",
      "Epoch 7 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.871779 [    0/  182]\n",
      "Batch 10 loss : 1.369295 [   20/  182]\n",
      "Batch 20 loss : 0.367326 [   40/  182]\n",
      "Batch 30 loss : 0.365104 [   60/  182]\n",
      "Batch 40 loss : 0.363123 [   80/  182]\n",
      "Batch 50 loss : 0.361191 [  100/  182]\n",
      "Batch 60 loss : 0.859169 [  120/  182]\n",
      "Batch 70 loss : 0.363769 [  140/  182]\n",
      "Batch 80 loss : 0.359955 [  160/  182]\n",
      "Batch 90 loss : 0.355906 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.291703\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.580539\n",
      "\n",
      "Epcoh time : 4.0분 52.39575791358948 초\n",
      "Epoch 8 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.855504 [    0/  182]\n",
      "Batch 10 loss : 0.852861 [   20/  182]\n",
      "Batch 20 loss : 0.350856 [   40/  182]\n",
      "Batch 30 loss : 0.349097 [   60/  182]\n",
      "Batch 40 loss : 0.362003 [   80/  182]\n",
      "Batch 50 loss : 0.362441 [  100/  182]\n",
      "Batch 60 loss : 0.355959 [  120/  182]\n",
      "Batch 70 loss : 0.350129 [  140/  182]\n",
      "Batch 80 loss : 0.346069 [  160/  182]\n",
      "Batch 90 loss : 0.843134 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.286424\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.567978\n",
      "\n",
      "Epcoh time : 4.0분 54.625606298446655 초\n",
      "Epoch 9 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.842822 [    0/  182]\n",
      "Batch 10 loss : 0.341109 [   20/  182]\n",
      "Batch 20 loss : 0.339384 [   40/  182]\n",
      "Batch 30 loss : 0.337797 [   60/  182]\n",
      "Batch 40 loss : 0.336407 [   80/  182]\n",
      "Batch 50 loss : 0.335185 [  100/  182]\n",
      "Batch 60 loss : 0.833658 [  120/  182]\n",
      "Batch 70 loss : 0.333795 [  140/  182]\n",
      "Batch 80 loss : 0.332455 [  160/  182]\n",
      "Batch 90 loss : 0.333292 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.278081\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.558333\n",
      "\n",
      "Epcoh time : 4.0분 56.95193028450012 초\n",
      "Epoch 10 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.333626 [    0/  182]\n",
      "Batch 10 loss : 0.333014 [   20/  182]\n",
      "Batch 20 loss : 0.330613 [   40/  182]\n",
      "Batch 30 loss : 0.328718 [   60/  182]\n",
      "Batch 40 loss : 0.327539 [   80/  182]\n",
      "Batch 50 loss : 0.328101 [  100/  182]\n",
      "Batch 60 loss : 0.826951 [  120/  182]\n",
      "Batch 70 loss : 0.825359 [  140/  182]\n",
      "Batch 80 loss : 0.824354 [  160/  182]\n",
      "Batch 90 loss : 0.330164 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.274088\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.566609\n",
      "\n",
      "Epcoh time : 4.0분 49.67352843284607 초\n",
      "Epoch 11 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.330256 [    0/  182]\n",
      "Batch 10 loss : 0.327800 [   20/  182]\n",
      "Batch 20 loss : 0.824544 [   40/  182]\n",
      "Batch 30 loss : 0.323273 [   60/  182]\n",
      "Batch 40 loss : 0.322181 [   80/  182]\n",
      "Batch 50 loss : 0.321232 [  100/  182]\n",
      "Batch 60 loss : 0.320699 [  120/  182]\n",
      "Batch 70 loss : 0.339245 [  140/  182]\n",
      "Batch 80 loss : 0.836645 [  160/  182]\n",
      "Batch 90 loss : 0.331729 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.272902\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.555662\n",
      "\n",
      "Epcoh time : 4.0분 42.32217836380005 초\n",
      "Epoch 12 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.330765 [    0/  182]\n",
      "Batch 10 loss : 0.824559 [   20/  182]\n",
      "Batch 20 loss : 0.821166 [   40/  182]\n",
      "Batch 30 loss : 0.321085 [   60/  182]\n",
      "Batch 40 loss : 0.320094 [   80/  182]\n",
      "Batch 50 loss : 0.319166 [  100/  182]\n",
      "Batch 60 loss : 0.818007 [  120/  182]\n",
      "Batch 70 loss : 0.319113 [  140/  182]\n",
      "Batch 80 loss : 0.817829 [  160/  182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 90 loss : 0.317913 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.270171\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.542982\n",
      "\n",
      "Epcoh time : 4.0분 44.45460224151611 초\n",
      "Epoch 13 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.317808 [    0/  182]\n",
      "Batch 10 loss : 0.317151 [   20/  182]\n",
      "Batch 20 loss : 0.316832 [   40/  182]\n",
      "Batch 30 loss : 0.316884 [   60/  182]\n",
      "Batch 40 loss : 0.316934 [   80/  182]\n",
      "Batch 50 loss : 0.815766 [  100/  182]\n",
      "Batch 60 loss : 0.815573 [  120/  182]\n",
      "Batch 70 loss : 0.316522 [  140/  182]\n",
      "Batch 80 loss : 0.815277 [  160/  182]\n",
      "Batch 90 loss : 0.316149 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.268101\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.540835\n",
      "\n",
      "Epcoh time : 4.0분 40.071062088012695 초\n",
      "Epoch 14 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.316109 [    0/  182]\n",
      "Batch 10 loss : 0.315960 [   20/  182]\n",
      "Batch 20 loss : 0.817634 [   40/  182]\n",
      "Batch 30 loss : 0.318985 [   60/  182]\n",
      "Batch 40 loss : 0.317387 [   80/  182]\n",
      "Batch 50 loss : 0.815522 [  100/  182]\n",
      "Batch 60 loss : 0.815456 [  120/  182]\n",
      "Batch 70 loss : 0.814955 [  140/  182]\n",
      "Batch 80 loss : 0.814859 [  160/  182]\n",
      "Batch 90 loss : 0.315208 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.268034\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.540792\n",
      "\n",
      "Epcoh time : 4.0분 42.77047157287598 초\n",
      "Epoch 15 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.315178 [    0/  182]\n",
      "Batch 10 loss : 0.814502 [   20/  182]\n",
      "Batch 20 loss : 0.315709 [   40/  182]\n",
      "Batch 30 loss : 0.315677 [   60/  182]\n",
      "Batch 40 loss : 0.315128 [   80/  182]\n",
      "Batch 50 loss : 0.814401 [  100/  182]\n",
      "Batch 60 loss : 0.314744 [  120/  182]\n",
      "Batch 70 loss : 1.313669 [  140/  182]\n",
      "Batch 80 loss : 0.314844 [  160/  182]\n",
      "Batch 90 loss : 0.314713 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.267274\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.539440\n",
      "\n",
      "Epcoh time : 4.0분 44.1780903339386 초\n",
      "Epoch 16 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314695 [    0/  182]\n",
      "Batch 10 loss : 0.314584 [   20/  182]\n",
      "Batch 20 loss : 0.814142 [   40/  182]\n",
      "Batch 30 loss : 0.814107 [   60/  182]\n",
      "Batch 40 loss : 0.314560 [   80/  182]\n",
      "Batch 50 loss : 0.314559 [  100/  182]\n",
      "Batch 60 loss : 0.314683 [  120/  182]\n",
      "Batch 70 loss : 1.311337 [  140/  182]\n",
      "Batch 80 loss : 0.314947 [  160/  182]\n",
      "Batch 90 loss : 0.314744 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.267073\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.539314\n",
      "\n",
      "Epcoh time : 4.0분 44.942811250686646 초\n",
      "Epoch 17 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314719 [    0/  182]\n",
      "Batch 10 loss : 0.813916 [   20/  182]\n",
      "Batch 20 loss : 0.314764 [   40/  182]\n",
      "Batch 30 loss : 0.813871 [   60/  182]\n",
      "Batch 40 loss : 0.314540 [   80/  182]\n",
      "Batch 50 loss : 0.813756 [  100/  182]\n",
      "Batch 60 loss : 0.314423 [  120/  182]\n",
      "Batch 70 loss : 0.314292 [  140/  182]\n",
      "Batch 80 loss : 0.813989 [  160/  182]\n",
      "Batch 90 loss : 0.314549 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.267005\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.542044\n",
      "\n",
      "Epcoh time : 4.0분 44.176708459854126 초\n",
      "Epoch 18 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813749 [    0/  182]\n",
      "Batch 10 loss : 0.314387 [   20/  182]\n",
      "Batch 20 loss : 0.314280 [   40/  182]\n",
      "Batch 30 loss : 0.813883 [   60/  182]\n",
      "Batch 40 loss : 1.313374 [   80/  182]\n",
      "Batch 50 loss : 0.314241 [  100/  182]\n",
      "Batch 60 loss : 0.314262 [  120/  182]\n",
      "Batch 70 loss : 0.314223 [  140/  182]\n",
      "Batch 80 loss : 0.314509 [  160/  182]\n",
      "Batch 90 loss : 0.314565 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266926\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.539048\n",
      "\n",
      "Epcoh time : 4.0분 44.43311929702759 초\n",
      "Epoch 19 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813338 [    0/  182]\n",
      "Batch 10 loss : 0.314338 [   20/  182]\n",
      "Batch 20 loss : 1.313223 [   40/  182]\n",
      "Batch 30 loss : 0.813642 [   60/  182]\n",
      "Batch 40 loss : 0.314391 [   80/  182]\n",
      "Batch 50 loss : 0.314178 [  100/  182]\n",
      "Batch 60 loss : 0.813771 [  120/  182]\n",
      "Batch 70 loss : 0.813765 [  140/  182]\n",
      "Batch 80 loss : 0.314079 [  160/  182]\n",
      "Batch 90 loss : 0.314194 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266880\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538878\n",
      "\n",
      "Epcoh time : 4.0분 44.424089193344116 초\n",
      "Epoch 20 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813533 [    0/  182]\n",
      "Batch 10 loss : 0.314160 [   20/  182]\n",
      "Batch 20 loss : 0.314085 [   40/  182]\n",
      "Batch 30 loss : 1.313496 [   60/  182]\n",
      "Batch 40 loss : 0.813592 [   80/  182]\n",
      "Batch 50 loss : 0.314229 [  100/  182]\n",
      "Batch 60 loss : 0.314240 [  120/  182]\n",
      "Batch 70 loss : 0.813274 [  140/  182]\n",
      "Batch 80 loss : 0.813385 [  160/  182]\n",
      "Batch 90 loss : 0.314107 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266842\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538859\n",
      "\n",
      "Epcoh time : 4.0분 45.26896357536316 초\n",
      "Epoch 21 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314089 [    0/  182]\n",
      "Batch 10 loss : 1.313311 [   20/  182]\n",
      "Batch 20 loss : 0.314020 [   40/  182]\n",
      "Batch 30 loss : 0.314018 [   60/  182]\n",
      "Batch 40 loss : 0.813628 [   80/  182]\n",
      "Batch 50 loss : 0.813611 [  100/  182]\n",
      "Batch 60 loss : 0.813445 [  120/  182]\n",
      "Batch 70 loss : 0.314054 [  140/  182]\n",
      "Batch 80 loss : 0.314015 [  160/  182]\n",
      "Batch 90 loss : 0.813531 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266820\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538827\n",
      "\n",
      "Epcoh time : 4.0분 45.74387192726135 초\n",
      "Epoch 22 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813513 [    0/  182]\n",
      "Batch 10 loss : 0.314099 [   20/  182]\n",
      "Batch 20 loss : 0.813551 [   40/  182]\n",
      "Batch 30 loss : 0.314017 [   60/  182]\n",
      "Batch 40 loss : 0.313991 [   80/  182]\n",
      "Batch 50 loss : 0.313981 [  100/  182]\n",
      "Batch 60 loss : 0.813621 [  120/  182]\n",
      "Batch 70 loss : 0.314062 [  140/  182]\n",
      "Batch 80 loss : 0.314139 [  160/  182]\n",
      "Batch 90 loss : 0.314533 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266808\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538817\n",
      "\n",
      "Epcoh time : 4.0분 45.37363386154175 초\n",
      "Epoch 23 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.812966 [    0/  182]\n",
      "Batch 10 loss : 0.314432 [   20/  182]\n",
      "Batch 20 loss : 0.314116 [   40/  182]\n",
      "Batch 30 loss : 0.313958 [   60/  182]\n",
      "Batch 40 loss : 0.813682 [   80/  182]\n",
      "Batch 50 loss : 0.813630 [  100/  182]\n",
      "Batch 60 loss : 0.314038 [  120/  182]\n",
      "Batch 70 loss : 0.314285 [  140/  182]\n",
      "Batch 80 loss : 0.813235 [  160/  182]\n",
      "Batch 90 loss : 0.314057 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266817\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538793\n",
      "\n",
      "Epcoh time : 4.0분 43.361204624176025 초\n",
      "Epoch 24 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314042 [    0/  182]\n",
      "Batch 10 loss : 0.313975 [   20/  182]\n",
      "Batch 20 loss : 0.813544 [   40/  182]\n",
      "Batch 30 loss : 0.313990 [   60/  182]\n",
      "Batch 40 loss : 0.313959 [   80/  182]\n",
      "Batch 50 loss : 0.313961 [  100/  182]\n",
      "Batch 60 loss : 0.813569 [  120/  182]\n",
      "Batch 70 loss : 0.813455 [  140/  182]\n",
      "Batch 80 loss : 1.312946 [  160/  182]\n",
      "Batch 90 loss : 0.314124 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266793\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538784\n",
      "\n",
      "Epcoh time : 4.0분 46.67858934402466 초\n",
      "Epoch 25 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813368 [    0/  182]\n",
      "Batch 10 loss : 0.314061 [   20/  182]\n",
      "Batch 20 loss : 0.313986 [   40/  182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 30 loss : 0.813545 [   60/  182]\n",
      "Batch 40 loss : 0.313993 [   80/  182]\n",
      "Batch 50 loss : 0.313989 [  100/  182]\n",
      "Batch 60 loss : 0.313946 [  120/  182]\n",
      "Batch 70 loss : 1.313296 [  140/  182]\n",
      "Batch 80 loss : 1.313071 [  160/  182]\n",
      "Batch 90 loss : 0.314261 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266792\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538787\n",
      "\n",
      "Epcoh time : 4.0분 43.07710027694702 초\n",
      "Epoch 26 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314281 [    0/  182]\n",
      "Batch 10 loss : 0.314329 [   20/  182]\n",
      "Batch 20 loss : 0.314259 [   40/  182]\n",
      "Batch 30 loss : 1.313143 [   60/  182]\n",
      "Batch 40 loss : 0.313960 [   80/  182]\n",
      "Batch 50 loss : 0.313932 [  100/  182]\n",
      "Batch 60 loss : 0.313928 [  120/  182]\n",
      "Batch 70 loss : 0.313930 [  140/  182]\n",
      "Batch 80 loss : 0.813630 [  160/  182]\n",
      "Batch 90 loss : 0.314122 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266800\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538781\n",
      "\n",
      "Epcoh time : 4.0분 45.18898010253906 초\n",
      "Epoch 27 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314148 [    0/  182]\n",
      "Batch 10 loss : 0.314192 [   20/  182]\n",
      "Batch 20 loss : 1.313049 [   40/  182]\n",
      "Batch 30 loss : 0.813497 [   60/  182]\n",
      "Batch 40 loss : 0.813534 [   80/  182]\n",
      "Batch 50 loss : 0.813546 [  100/  182]\n",
      "Batch 60 loss : 0.313997 [  120/  182]\n",
      "Batch 70 loss : 0.813428 [  140/  182]\n",
      "Batch 80 loss : 0.314102 [  160/  182]\n",
      "Batch 90 loss : 0.314108 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266793\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538779\n",
      "\n",
      "Epcoh time : 4.0분 46.12027025222778 초\n",
      "Epoch 28 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813364 [    0/  182]\n",
      "Batch 10 loss : 0.314185 [   20/  182]\n",
      "Batch 20 loss : 0.314095 [   40/  182]\n",
      "Batch 30 loss : 0.314222 [   60/  182]\n",
      "Batch 40 loss : 0.314063 [   80/  182]\n",
      "Batch 50 loss : 0.813604 [  100/  182]\n",
      "Batch 60 loss : 0.313978 [  120/  182]\n",
      "Batch 70 loss : 0.313969 [  140/  182]\n",
      "Batch 80 loss : 0.313947 [  160/  182]\n",
      "Batch 90 loss : 0.813524 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266796\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551271\n",
      "\n",
      "Epcoh time : 4.0분 44.398736000061035 초\n",
      "Epoch 29 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314004 [    0/  182]\n",
      "Batch 10 loss : 0.314085 [   20/  182]\n",
      "Batch 20 loss : 0.314032 [   40/  182]\n",
      "Batch 30 loss : 0.314024 [   60/  182]\n",
      "Batch 40 loss : 0.813459 [   80/  182]\n",
      "Batch 50 loss : 0.813263 [  100/  182]\n",
      "Batch 60 loss : 0.314306 [  120/  182]\n",
      "Batch 70 loss : 1.313155 [  140/  182]\n",
      "Batch 80 loss : 0.813606 [  160/  182]\n",
      "Batch 90 loss : 0.313947 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266796\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538793\n",
      "\n",
      "Epcoh time : 4.0분 44.122108459472656 초\n",
      "Epoch 30 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313947 [    0/  182]\n",
      "Batch 10 loss : 0.313941 [   20/  182]\n",
      "Batch 20 loss : 0.813618 [   40/  182]\n",
      "Batch 30 loss : 0.313982 [   60/  182]\n",
      "Batch 40 loss : 0.813433 [   80/  182]\n",
      "Batch 50 loss : 0.314291 [  100/  182]\n",
      "Batch 60 loss : 0.314071 [  120/  182]\n",
      "Batch 70 loss : 0.314066 [  140/  182]\n",
      "Batch 80 loss : 0.314080 [  160/  182]\n",
      "Batch 90 loss : 0.314029 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266791\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538780\n",
      "\n",
      "Epcoh time : 4.0분 45.99264049530029 초\n",
      "Epoch 31 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813487 [    0/  182]\n",
      "Batch 10 loss : 0.314049 [   20/  182]\n",
      "Batch 20 loss : 0.813479 [   40/  182]\n",
      "Batch 30 loss : 0.314090 [   60/  182]\n",
      "Batch 40 loss : 1.312547 [   80/  182]\n",
      "Batch 50 loss : 1.312526 [  100/  182]\n",
      "Batch 60 loss : 0.813330 [  120/  182]\n",
      "Batch 70 loss : 0.314060 [  140/  182]\n",
      "Batch 80 loss : 0.313997 [  160/  182]\n",
      "Batch 90 loss : 0.313970 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266786\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538786\n",
      "\n",
      "Epcoh time : 4.0분 46.54163646697998 초\n",
      "Epoch 32 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313967 [    0/  182]\n",
      "Batch 10 loss : 0.813613 [   20/  182]\n",
      "Batch 20 loss : 0.313937 [   40/  182]\n",
      "Batch 30 loss : 1.313188 [   60/  182]\n",
      "Batch 40 loss : 0.314003 [   80/  182]\n",
      "Batch 50 loss : 0.313979 [  100/  182]\n",
      "Batch 60 loss : 0.813510 [  120/  182]\n",
      "Batch 70 loss : 0.813567 [  140/  182]\n",
      "Batch 80 loss : 0.313967 [  160/  182]\n",
      "Batch 90 loss : 0.314076 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266789\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538775\n",
      "\n",
      "Epcoh time : 4.0분 44.15277600288391 초\n",
      "Epoch 33 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314086 [    0/  182]\n",
      "Batch 10 loss : 0.313982 [   20/  182]\n",
      "Batch 20 loss : 0.313915 [   40/  182]\n",
      "Batch 30 loss : 0.313907 [   60/  182]\n",
      "Batch 40 loss : 0.813662 [   80/  182]\n",
      "Batch 50 loss : 0.313984 [  100/  182]\n",
      "Batch 60 loss : 0.314320 [  120/  182]\n",
      "Batch 70 loss : 0.314045 [  140/  182]\n",
      "Batch 80 loss : 0.813612 [  160/  182]\n",
      "Batch 90 loss : 0.314006 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266804\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538778\n",
      "\n",
      "Epcoh time : 4.0분 44.471431255340576 초\n",
      "Epoch 34 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314012 [    0/  182]\n",
      "Batch 10 loss : 0.314029 [   20/  182]\n",
      "Batch 20 loss : 0.314109 [   40/  182]\n",
      "Batch 30 loss : 0.314026 [   60/  182]\n",
      "Batch 40 loss : 0.314117 [   80/  182]\n",
      "Batch 50 loss : 0.314028 [  100/  182]\n",
      "Batch 60 loss : 0.314033 [  120/  182]\n",
      "Batch 70 loss : 0.314042 [  140/  182]\n",
      "Batch 80 loss : 0.813520 [  160/  182]\n",
      "Batch 90 loss : 0.813553 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266789\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538782\n",
      "\n",
      "Epcoh time : 4.0분 45.709911584854126 초\n",
      "Epoch 35 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313973 [    0/  182]\n",
      "Batch 10 loss : 0.314059 [   20/  182]\n",
      "Batch 20 loss : 0.314056 [   40/  182]\n",
      "Batch 30 loss : 0.314103 [   60/  182]\n",
      "Batch 40 loss : 0.314067 [   80/  182]\n",
      "Batch 50 loss : 0.813389 [  100/  182]\n",
      "Batch 60 loss : 0.314259 [  120/  182]\n",
      "Batch 70 loss : 0.314067 [  140/  182]\n",
      "Batch 80 loss : 0.313976 [  160/  182]\n",
      "Batch 90 loss : 0.813629 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266790\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538794\n",
      "\n",
      "Epcoh time : 4.0분 45.102426528930664 초\n",
      "Epoch 36 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 37\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813628 [    0/  182]\n",
      "Batch 10 loss : 0.313941 [   20/  182]\n",
      "Batch 20 loss : 0.313939 [   40/  182]\n",
      "Batch 30 loss : 0.313917 [   60/  182]\n",
      "Batch 40 loss : 0.313919 [   80/  182]\n",
      "Batch 50 loss : 0.813516 [  100/  182]\n",
      "Batch 60 loss : 0.813383 [  120/  182]\n",
      "Batch 70 loss : 0.314076 [  140/  182]\n",
      "Batch 80 loss : 0.813511 [  160/  182]\n",
      "Batch 90 loss : 0.813461 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266788\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538774\n",
      "\n",
      "Epcoh time : 4.0분 43.917672872543335 초\n",
      "Epoch 37 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 38\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813445 [    0/  182]\n",
      "Batch 10 loss : 0.314841 [   20/  182]\n",
      "Batch 20 loss : 0.314392 [   40/  182]\n",
      "Batch 30 loss : 0.313933 [   60/  182]\n",
      "Batch 40 loss : 0.313893 [   80/  182]\n",
      "Batch 50 loss : 0.813772 [  100/  182]\n",
      "Batch 60 loss : 0.313893 [  120/  182]\n",
      "Batch 70 loss : 0.813677 [  140/  182]\n",
      "Batch 80 loss : 0.813649 [  160/  182]\n",
      "Batch 90 loss : 0.813588 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266825\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538785\n",
      "\n",
      "Epcoh time : 4.0분 44.910073041915894 초\n",
      "Epoch 38 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 39\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 loss : 0.313950 [    0/  182]\n",
      "Batch 10 loss : 0.313955 [   20/  182]\n",
      "Batch 20 loss : 0.313927 [   40/  182]\n",
      "Batch 30 loss : 1.313301 [   60/  182]\n",
      "Batch 40 loss : 0.314003 [   80/  182]\n",
      "Batch 50 loss : 0.813495 [  100/  182]\n",
      "Batch 60 loss : 0.813570 [  120/  182]\n",
      "Batch 70 loss : 0.813541 [  140/  182]\n",
      "Batch 80 loss : 0.314061 [  160/  182]\n",
      "Batch 90 loss : 0.314135 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266785\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551251\n",
      "\n",
      "Epcoh time : 4.0분 43.45014214515686 초\n",
      "Epoch 39 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 40\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813300 [    0/  182]\n",
      "Batch 10 loss : 0.314232 [   20/  182]\n",
      "Batch 20 loss : 0.813241 [   40/  182]\n",
      "Batch 30 loss : 0.813323 [   60/  182]\n",
      "Batch 40 loss : 0.813426 [   80/  182]\n",
      "Batch 50 loss : 0.314037 [  100/  182]\n",
      "Batch 60 loss : 0.313989 [  120/  182]\n",
      "Batch 70 loss : 0.813538 [  140/  182]\n",
      "Batch 80 loss : 0.314023 [  160/  182]\n",
      "Batch 90 loss : 0.314072 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266789\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551255\n",
      "\n",
      "Epcoh time : 4.0분 45.33287811279297 초\n",
      "Epoch 40 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 41\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314067 [    0/  182]\n",
      "Batch 10 loss : 0.813503 [   20/  182]\n",
      "Batch 20 loss : 0.314282 [   40/  182]\n",
      "Batch 30 loss : 1.312512 [   60/  182]\n",
      "Batch 40 loss : 0.314047 [   80/  182]\n",
      "Batch 50 loss : 0.813636 [  100/  182]\n",
      "Batch 60 loss : 0.313932 [  120/  182]\n",
      "Batch 70 loss : 0.313961 [  140/  182]\n",
      "Batch 80 loss : 0.313968 [  160/  182]\n",
      "Batch 90 loss : 0.313963 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266797\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551271\n",
      "\n",
      "Epcoh time : 4.0분 44.995237827301025 초\n",
      "Epoch 41 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 42\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313959 [    0/  182]\n",
      "Batch 10 loss : 0.313953 [   20/  182]\n",
      "Batch 20 loss : 0.313981 [   40/  182]\n",
      "Batch 30 loss : 0.314064 [   60/  182]\n",
      "Batch 40 loss : 0.314045 [   80/  182]\n",
      "Batch 50 loss : 0.314042 [  100/  182]\n",
      "Batch 60 loss : 0.813449 [  120/  182]\n",
      "Batch 70 loss : 1.313042 [  140/  182]\n",
      "Batch 80 loss : 0.314012 [  160/  182]\n",
      "Batch 90 loss : 0.314048 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266786\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538771\n",
      "\n",
      "Epcoh time : 4.0분 42.174274921417236 초\n",
      "Epoch 42 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 43\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314036 [    0/  182]\n",
      "Batch 10 loss : 0.313988 [   20/  182]\n",
      "Batch 20 loss : 0.314021 [   40/  182]\n",
      "Batch 30 loss : 0.314014 [   60/  182]\n",
      "Batch 40 loss : 0.314012 [   80/  182]\n",
      "Batch 50 loss : 0.813603 [  100/  182]\n",
      "Batch 60 loss : 0.313943 [  120/  182]\n",
      "Batch 70 loss : 0.813581 [  140/  182]\n",
      "Batch 80 loss : 0.813478 [  160/  182]\n",
      "Batch 90 loss : 0.813389 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266789\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538770\n",
      "\n",
      "Epcoh time : 4.0분 44.456186294555664 초\n",
      "Epoch 43 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 44\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813399 [    0/  182]\n",
      "Batch 10 loss : 0.813508 [   20/  182]\n",
      "Batch 20 loss : 0.314010 [   40/  182]\n",
      "Batch 30 loss : 0.313934 [   60/  182]\n",
      "Batch 40 loss : 0.313922 [   80/  182]\n",
      "Batch 50 loss : 0.813623 [  100/  182]\n",
      "Batch 60 loss : 0.313986 [  120/  182]\n",
      "Batch 70 loss : 0.813484 [  140/  182]\n",
      "Batch 80 loss : 0.314015 [  160/  182]\n",
      "Batch 90 loss : 0.314263 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266786\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538775\n",
      "\n",
      "Epcoh time : 4.0분 45.381160259246826 초\n",
      "Epoch 44 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 45\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 1.312085 [    0/  182]\n",
      "Batch 10 loss : 0.314777 [   20/  182]\n",
      "Batch 20 loss : 1.309171 [   40/  182]\n",
      "Batch 30 loss : 0.811514 [   60/  182]\n",
      "Batch 40 loss : 0.315938 [   80/  182]\n",
      "Batch 50 loss : 0.813112 [  100/  182]\n",
      "Batch 60 loss : 0.313967 [  120/  182]\n",
      "Batch 70 loss : 0.813665 [  140/  182]\n",
      "Batch 80 loss : 0.813678 [  160/  182]\n",
      "Batch 90 loss : 0.813667 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266841\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538799\n",
      "\n",
      "Epcoh time : 4.0분 43.767815828323364 초\n",
      "Epoch 45 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 46\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313908 [    0/  182]\n",
      "Batch 10 loss : 0.313916 [   20/  182]\n",
      "Batch 20 loss : 0.313929 [   40/  182]\n",
      "Batch 30 loss : 0.813595 [   60/  182]\n",
      "Batch 40 loss : 0.313942 [   80/  182]\n",
      "Batch 50 loss : 0.813562 [  100/  182]\n",
      "Batch 60 loss : 0.313980 [  120/  182]\n",
      "Batch 70 loss : 0.314025 [  140/  182]\n",
      "Batch 80 loss : 0.813434 [  160/  182]\n",
      "Batch 90 loss : 0.314016 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266786\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551259\n",
      "\n",
      "Epcoh time : 4.0분 44.27054953575134 초\n",
      "Epoch 46 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 47\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314011 [    0/  182]\n",
      "Batch 10 loss : 1.312851 [   20/  182]\n",
      "Batch 20 loss : 0.314137 [   40/  182]\n",
      "Batch 30 loss : 0.314104 [   60/  182]\n",
      "Batch 40 loss : 0.314093 [   80/  182]\n",
      "Batch 50 loss : 0.813462 [  100/  182]\n",
      "Batch 60 loss : 0.314015 [  120/  182]\n",
      "Batch 70 loss : 0.314000 [  140/  182]\n",
      "Batch 80 loss : 0.314034 [  160/  182]\n",
      "Batch 90 loss : 0.314003 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266783\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538773\n",
      "\n",
      "Epcoh time : 4.0분 43.802324056625366 초\n",
      "Epoch 47 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 48\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813501 [    0/  182]\n",
      "Batch 10 loss : 0.313939 [   20/  182]\n",
      "Batch 20 loss : 0.313931 [   40/  182]\n",
      "Batch 30 loss : 0.313928 [   60/  182]\n",
      "Batch 40 loss : 0.313949 [   80/  182]\n",
      "Batch 50 loss : 0.313997 [  100/  182]\n",
      "Batch 60 loss : 0.314063 [  120/  182]\n",
      "Batch 70 loss : 1.312867 [  140/  182]\n",
      "Batch 80 loss : 0.813334 [  160/  182]\n",
      "Batch 90 loss : 0.314094 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266786\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538768\n",
      "\n",
      "Epcoh time : 4.0분 46.62743544578552 초\n",
      "Epoch 48 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 49\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314086 [    0/  182]\n",
      "Batch 10 loss : 0.813464 [   20/  182]\n",
      "Batch 20 loss : 0.813499 [   40/  182]\n",
      "Batch 30 loss : 0.813404 [   60/  182]\n",
      "Batch 40 loss : 1.312883 [   80/  182]\n",
      "Batch 50 loss : 0.314060 [  100/  182]\n",
      "Batch 60 loss : 0.314043 [  120/  182]\n",
      "Batch 70 loss : 0.813568 [  140/  182]\n",
      "Batch 80 loss : 0.313923 [  160/  182]\n",
      "Batch 90 loss : 0.813590 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266787\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538781\n",
      "\n",
      "Epcoh time : 4.0분 47.913376808166504 초\n",
      "Epoch 49 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313948 [    0/  182]\n",
      "Batch 10 loss : 0.813532 [   20/  182]\n",
      "Batch 20 loss : 0.813571 [   40/  182]\n",
      "Batch 30 loss : 0.813565 [   60/  182]\n",
      "Batch 40 loss : 0.314069 [   80/  182]\n",
      "Batch 50 loss : 0.314011 [  100/  182]\n",
      "Batch 60 loss : 0.314253 [  120/  182]\n",
      "Batch 70 loss : 0.314629 [  140/  182]\n",
      "Batch 80 loss : 0.812972 [  160/  182]\n",
      "Batch 90 loss : 0.314084 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266797\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538769\n",
      "\n",
      "Epcoh time : 4.0분 45.118138790130615 초\n",
      "Epoch 50 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 51\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813427 [    0/  182]\n",
      "Batch 10 loss : 0.813659 [   20/  182]\n",
      "Batch 20 loss : 1.313516 [   40/  182]\n",
      "Batch 30 loss : 0.813688 [   60/  182]\n",
      "Batch 40 loss : 0.313938 [   80/  182]\n",
      "Batch 50 loss : 0.313970 [  100/  182]\n",
      "Batch 60 loss : 0.813563 [  120/  182]\n",
      "Batch 70 loss : 0.813500 [  140/  182]\n",
      "Batch 80 loss : 0.813359 [  160/  182]\n",
      "Batch 90 loss : 0.314060 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266795\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538769\n",
      "\n",
      "Epcoh time : 4.0분 44.58966112136841 초\n",
      "Epoch 51 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 52\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813443 [    0/  182]\n",
      "Batch 10 loss : 0.313933 [   20/  182]\n",
      "Batch 20 loss : 0.313926 [   40/  182]\n",
      "Batch 30 loss : 0.813614 [   60/  182]\n",
      "Batch 40 loss : 0.313929 [   80/  182]\n",
      "Batch 50 loss : 0.813535 [  100/  182]\n",
      "Batch 60 loss : 0.314091 [  120/  182]\n",
      "Batch 70 loss : 0.314022 [  140/  182]\n",
      "Batch 80 loss : 0.313996 [  160/  182]\n",
      "Batch 90 loss : 0.813449 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266785\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538769\n",
      "\n",
      "Epcoh time : 4.0분 46.03272986412048 초\n",
      "Epoch 52 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 53\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314034 [    0/  182]\n",
      "Batch 10 loss : 0.314206 [   20/  182]\n",
      "Batch 20 loss : 0.314273 [   40/  182]\n",
      "Batch 30 loss : 0.314004 [   60/  182]\n",
      "Batch 40 loss : 0.313936 [   80/  182]\n",
      "Batch 50 loss : 1.313437 [  100/  182]\n",
      "Batch 60 loss : 0.313924 [  120/  182]\n",
      "Batch 70 loss : 0.313949 [  140/  182]\n",
      "Batch 80 loss : 0.313994 [  160/  182]\n",
      "Batch 90 loss : 0.314059 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266791\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538767\n",
      "\n",
      "Epcoh time : 4.0분 44.57016658782959 초\n",
      "Epoch 53 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 54\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314059 [    0/  182]\n",
      "Batch 10 loss : 0.313985 [   20/  182]\n",
      "Batch 20 loss : 0.313969 [   40/  182]\n",
      "Batch 30 loss : 0.313949 [   60/  182]\n",
      "Batch 40 loss : 0.813559 [   80/  182]\n",
      "Batch 50 loss : 1.312763 [  100/  182]\n",
      "Batch 60 loss : 0.314559 [  120/  182]\n",
      "Batch 70 loss : 0.314648 [  140/  182]\n",
      "Batch 80 loss : 0.314080 [  160/  182]\n",
      "Batch 90 loss : 0.813555 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266798\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538778\n",
      "\n",
      "Epcoh time : 4.0분 45.55051040649414 초\n",
      "Epoch 54 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 55\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313953 [    0/  182]\n",
      "Batch 10 loss : 1.313311 [   20/  182]\n",
      "Batch 20 loss : 0.813543 [   40/  182]\n",
      "Batch 30 loss : 0.313983 [   60/  182]\n",
      "Batch 40 loss : 0.313987 [   80/  182]\n",
      "Batch 50 loss : 0.314016 [  100/  182]\n",
      "Batch 60 loss : 0.813344 [  120/  182]\n",
      "Batch 70 loss : 0.314171 [  140/  182]\n",
      "Batch 80 loss : 0.813397 [  160/  182]\n",
      "Batch 90 loss : 0.313986 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266787\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538774\n",
      "\n",
      "Epcoh time : 4.0분 44.04055643081665 초\n",
      "Epoch 55 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 56\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313973 [    0/  182]\n",
      "Batch 10 loss : 0.313931 [   20/  182]\n",
      "Batch 20 loss : 0.313918 [   40/  182]\n",
      "Batch 30 loss : 0.813632 [   60/  182]\n",
      "Batch 40 loss : 0.313928 [   80/  182]\n",
      "Batch 50 loss : 0.813623 [  100/  182]\n",
      "Batch 60 loss : 0.813493 [  120/  182]\n",
      "Batch 70 loss : 0.813261 [  140/  182]\n",
      "Batch 80 loss : 0.813322 [  160/  182]\n",
      "Batch 90 loss : 0.314039 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266787\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538768\n",
      "\n",
      "Epcoh time : 4.0분 44.40617561340332 초\n",
      "Epoch 56 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 57\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813445 [    0/  182]\n",
      "Batch 10 loss : 0.813505 [   20/  182]\n",
      "Batch 20 loss : 0.314045 [   40/  182]\n",
      "Batch 30 loss : 0.813537 [   60/  182]\n",
      "Batch 40 loss : 0.313946 [   80/  182]\n",
      "Batch 50 loss : 0.314000 [  100/  182]\n",
      "Batch 60 loss : 0.314079 [  120/  182]\n",
      "Batch 70 loss : 0.813479 [  140/  182]\n",
      "Batch 80 loss : 0.314002 [  160/  182]\n",
      "Batch 90 loss : 0.813523 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266785\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551260\n",
      "\n",
      "Epcoh time : 4.0분 46.62600588798523 초\n",
      "Epoch 57 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 58\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313980 [    0/  182]\n",
      "Batch 10 loss : 0.813546 [   20/  182]\n",
      "Batch 20 loss : 0.313993 [   40/  182]\n",
      "Batch 30 loss : 0.314079 [   60/  182]\n",
      "Batch 40 loss : 0.813279 [   80/  182]\n",
      "Batch 50 loss : 0.813168 [  100/  182]\n",
      "Batch 60 loss : 0.813272 [  120/  182]\n",
      "Batch 70 loss : 1.312165 [  140/  182]\n",
      "Batch 80 loss : 0.813161 [  160/  182]\n",
      "Batch 90 loss : 0.314066 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266786\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538767\n",
      "\n",
      "Epcoh time : 4.0분 43.19403290748596 초\n",
      "Epoch 58 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 59\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314037 [    0/  182]\n",
      "Batch 10 loss : 0.313919 [   20/  182]\n",
      "Batch 20 loss : 0.313916 [   40/  182]\n",
      "Batch 30 loss : 0.313934 [   60/  182]\n",
      "Batch 40 loss : 0.313984 [   80/  182]\n",
      "Batch 50 loss : 0.314009 [  100/  182]\n",
      "Batch 60 loss : 0.314016 [  120/  182]\n",
      "Batch 70 loss : 0.313985 [  140/  182]\n",
      "Batch 80 loss : 0.313975 [  160/  182]\n",
      "Batch 90 loss : 0.313963 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266786\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538774\n",
      "\n",
      "Epcoh time : 4.0분 46.05947804450989 초\n",
      "Epoch 59 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 60\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313963 [    0/  182]\n",
      "Batch 10 loss : 0.313959 [   20/  182]\n",
      "Batch 20 loss : 0.314023 [   40/  182]\n",
      "Batch 30 loss : 0.813335 [   60/  182]\n",
      "Batch 40 loss : 0.813421 [   80/  182]\n",
      "Batch 50 loss : 0.314022 [  100/  182]\n",
      "Batch 60 loss : 0.314001 [  120/  182]\n",
      "Batch 70 loss : 0.813527 [  140/  182]\n",
      "Batch 80 loss : 0.314049 [  160/  182]\n",
      "Batch 90 loss : 0.314013 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266785\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538769\n",
      "\n",
      "Epcoh time : 4.0분 45.61853098869324 초\n",
      "Epoch 60 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 61\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314005 [    0/  182]\n",
      "Batch 10 loss : 0.313947 [   20/  182]\n",
      "Batch 20 loss : 0.313917 [   40/  182]\n",
      "Batch 30 loss : 0.313922 [   60/  182]\n",
      "Batch 40 loss : 0.813572 [   80/  182]\n",
      "Batch 50 loss : 0.813514 [  100/  182]\n",
      "Batch 60 loss : 0.813542 [  120/  182]\n",
      "Batch 70 loss : 0.313965 [  140/  182]\n",
      "Batch 80 loss : 0.314015 [  160/  182]\n",
      "Batch 90 loss : 1.312624 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266778\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538765\n",
      "\n",
      "Epcoh time : 4.0분 46.23093867301941 초\n",
      "Epoch 61 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 62\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314135 [    0/  182]\n",
      "Batch 10 loss : 0.813420 [   20/  182]\n",
      "Batch 20 loss : 0.314065 [   40/  182]\n",
      "Batch 30 loss : 0.813376 [   60/  182]\n",
      "Batch 40 loss : 0.314077 [   80/  182]\n",
      "Batch 50 loss : 0.813390 [  100/  182]\n",
      "Batch 60 loss : 0.813415 [  120/  182]\n",
      "Batch 70 loss : 0.813487 [  140/  182]\n",
      "Batch 80 loss : 0.813510 [  160/  182]\n",
      "Batch 90 loss : 0.813482 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266787\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538767\n",
      "\n",
      "Epcoh time : 4.0분 45.27944850921631 초\n",
      "Epoch 62 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 63\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314017 [    0/  182]\n",
      "Batch 10 loss : 0.313999 [   20/  182]\n",
      "Batch 20 loss : 0.313951 [   40/  182]\n",
      "Batch 30 loss : 0.313966 [   60/  182]\n",
      "Batch 40 loss : 0.813490 [   80/  182]\n",
      "Batch 50 loss : 0.314024 [  100/  182]\n",
      "Batch 60 loss : 0.314000 [  120/  182]\n",
      "Batch 70 loss : 0.314062 [  140/  182]\n",
      "Batch 80 loss : 0.314177 [  160/  182]\n",
      "Batch 90 loss : 0.314208 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266783\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538767\n",
      "\n",
      "Epcoh time : 4.0분 44.94484758377075 초\n",
      "Epoch 63 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 64\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314205 [    0/  182]\n",
      "Batch 10 loss : 0.813487 [   20/  182]\n",
      "Batch 20 loss : 0.313928 [   40/  182]\n",
      "Batch 30 loss : 0.313914 [   60/  182]\n",
      "Batch 40 loss : 0.313941 [   80/  182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50 loss : 1.313093 [  100/  182]\n",
      "Batch 60 loss : 0.813314 [  120/  182]\n",
      "Batch 70 loss : 0.314117 [  140/  182]\n",
      "Batch 80 loss : 0.314099 [  160/  182]\n",
      "Batch 90 loss : 0.314068 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266790\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551248\n",
      "\n",
      "Epcoh time : 4.0분 42.223129749298096 초\n",
      "Epoch 64 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 65\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314068 [    0/  182]\n",
      "Batch 10 loss : 0.813485 [   20/  182]\n",
      "Batch 20 loss : 0.313987 [   40/  182]\n",
      "Batch 30 loss : 0.813535 [   60/  182]\n",
      "Batch 40 loss : 0.813563 [   80/  182]\n",
      "Batch 50 loss : 0.313951 [  100/  182]\n",
      "Batch 60 loss : 0.313935 [  120/  182]\n",
      "Batch 70 loss : 1.313292 [  140/  182]\n",
      "Batch 80 loss : 0.314034 [  160/  182]\n",
      "Batch 90 loss : 0.314283 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266782\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538773\n",
      "\n",
      "Epcoh time : 4.0분 44.98695635795593 초\n",
      "Epoch 65 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 66\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314297 [    0/  182]\n",
      "Batch 10 loss : 0.314315 [   20/  182]\n",
      "Batch 20 loss : 0.314610 [   40/  182]\n",
      "Batch 30 loss : 0.314506 [   60/  182]\n",
      "Batch 40 loss : 0.314588 [   80/  182]\n",
      "Batch 50 loss : 0.314873 [  100/  182]\n",
      "Batch 60 loss : 0.812836 [  120/  182]\n",
      "Batch 70 loss : 0.314326 [  140/  182]\n",
      "Batch 80 loss : 0.314212 [  160/  182]\n",
      "Batch 90 loss : 0.314017 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266790\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538768\n",
      "\n",
      "Epcoh time : 4.0분 43.477203130722046 초\n",
      "Epoch 66 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 67\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 1.312966 [    0/  182]\n",
      "Batch 10 loss : 0.313974 [   20/  182]\n",
      "Batch 20 loss : 0.313950 [   40/  182]\n",
      "Batch 30 loss : 0.313941 [   60/  182]\n",
      "Batch 40 loss : 0.313950 [   80/  182]\n",
      "Batch 50 loss : 0.313958 [  100/  182]\n",
      "Batch 60 loss : 0.313939 [  120/  182]\n",
      "Batch 70 loss : 0.813601 [  140/  182]\n",
      "Batch 80 loss : 1.313200 [  160/  182]\n",
      "Batch 90 loss : 0.813507 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266780\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538769\n",
      "\n",
      "Epcoh time : 4.0분 44.27200746536255 초\n",
      "Epoch 67 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 68\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813494 [    0/  182]\n",
      "Batch 10 loss : 0.813226 [   20/  182]\n",
      "Batch 20 loss : 0.813259 [   40/  182]\n",
      "Batch 30 loss : 0.314174 [   60/  182]\n",
      "Batch 40 loss : 0.314041 [   80/  182]\n",
      "Batch 50 loss : 0.813566 [  100/  182]\n",
      "Batch 60 loss : 0.813606 [  120/  182]\n",
      "Batch 70 loss : 0.313961 [  140/  182]\n",
      "Batch 80 loss : 0.314007 [  160/  182]\n",
      "Batch 90 loss : 0.313991 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266789\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538769\n",
      "\n",
      "Epcoh time : 4.0분 43.83450889587402 초\n",
      "Epoch 68 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 69\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313990 [    0/  182]\n",
      "Batch 10 loss : 0.813562 [   20/  182]\n",
      "Batch 20 loss : 0.313949 [   40/  182]\n",
      "Batch 30 loss : 0.813529 [   60/  182]\n",
      "Batch 40 loss : 0.313962 [   80/  182]\n",
      "Batch 50 loss : 0.813496 [  100/  182]\n",
      "Batch 60 loss : 0.314130 [  120/  182]\n",
      "Batch 70 loss : 0.314137 [  140/  182]\n",
      "Batch 80 loss : 0.314059 [  160/  182]\n",
      "Batch 90 loss : 0.314050 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266781\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551249\n",
      "\n",
      "Epcoh time : 4.0분 44.81072282791138 초\n",
      "Epoch 69 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 70\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314051 [    0/  182]\n",
      "Batch 10 loss : 0.813340 [   20/  182]\n",
      "Batch 20 loss : 0.314167 [   40/  182]\n",
      "Batch 30 loss : 0.813373 [   60/  182]\n",
      "Batch 40 loss : 0.813468 [   80/  182]\n",
      "Batch 50 loss : 1.312771 [  100/  182]\n",
      "Batch 60 loss : 0.813278 [  120/  182]\n",
      "Batch 70 loss : 0.314106 [  140/  182]\n",
      "Batch 80 loss : 0.313955 [  160/  182]\n",
      "Batch 90 loss : 0.313935 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266785\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538780\n",
      "\n",
      "Epcoh time : 4.0분 44.817686319351196 초\n",
      "Epoch 70 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 71\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313935 [    0/  182]\n",
      "Batch 10 loss : 0.313936 [   20/  182]\n",
      "Batch 20 loss : 0.813567 [   40/  182]\n",
      "Batch 30 loss : 0.313974 [   60/  182]\n",
      "Batch 40 loss : 0.813553 [   80/  182]\n",
      "Batch 50 loss : 0.813280 [  100/  182]\n",
      "Batch 60 loss : 0.314435 [  120/  182]\n",
      "Batch 70 loss : 0.314045 [  140/  182]\n",
      "Batch 80 loss : 0.313931 [  160/  182]\n",
      "Batch 90 loss : 1.313444 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266795\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538797\n",
      "\n",
      "Epcoh time : 4.0분 45.13914203643799 초\n",
      "Epoch 71 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 72\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313899 [    0/  182]\n",
      "Batch 10 loss : 0.313915 [   20/  182]\n",
      "Batch 20 loss : 0.813504 [   40/  182]\n",
      "Batch 30 loss : 0.314171 [   60/  182]\n",
      "Batch 40 loss : 0.314262 [   80/  182]\n",
      "Batch 50 loss : 0.314003 [  100/  182]\n",
      "Batch 60 loss : 0.313930 [  120/  182]\n",
      "Batch 70 loss : 0.313906 [  140/  182]\n",
      "Batch 80 loss : 1.313462 [  160/  182]\n",
      "Batch 90 loss : 0.813655 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266793\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551284\n",
      "\n",
      "Epcoh time : 4.0분 43.69192552566528 초\n",
      "Epoch 72 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 73\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313907 [    0/  182]\n",
      "Batch 10 loss : 0.813583 [   20/  182]\n",
      "Batch 20 loss : 0.813455 [   40/  182]\n",
      "Batch 30 loss : 0.314107 [   60/  182]\n",
      "Batch 40 loss : 0.813279 [   80/  182]\n",
      "Batch 50 loss : 0.314090 [  100/  182]\n",
      "Batch 60 loss : 0.313954 [  120/  182]\n",
      "Batch 70 loss : 0.813680 [  140/  182]\n",
      "Batch 80 loss : 0.813690 [  160/  182]\n",
      "Batch 90 loss : 0.813630 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266790\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551276\n",
      "\n",
      "Epcoh time : 4.0분 44.73940563201904 초\n",
      "Epoch 73 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 74\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313921 [    0/  182]\n",
      "Batch 10 loss : 0.813401 [   20/  182]\n",
      "Batch 20 loss : 0.314423 [   40/  182]\n",
      "Batch 30 loss : 0.314338 [   60/  182]\n",
      "Batch 40 loss : 0.314566 [   80/  182]\n",
      "Batch 50 loss : 0.314374 [  100/  182]\n",
      "Batch 60 loss : 0.313996 [  120/  182]\n",
      "Batch 70 loss : 0.313938 [  140/  182]\n",
      "Batch 80 loss : 0.313916 [  160/  182]\n",
      "Batch 90 loss : 0.313912 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266795\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538788\n",
      "\n",
      "Epcoh time : 4.0분 45.14951181411743 초\n",
      "Epoch 74 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313911 [    0/  182]\n",
      "Batch 10 loss : 0.313903 [   20/  182]\n",
      "Batch 20 loss : 0.813640 [   40/  182]\n",
      "Batch 30 loss : 0.313928 [   60/  182]\n",
      "Batch 40 loss : 0.313923 [   80/  182]\n",
      "Batch 50 loss : 0.813558 [  100/  182]\n",
      "Batch 60 loss : 0.314091 [  120/  182]\n",
      "Batch 70 loss : 0.314108 [  140/  182]\n",
      "Batch 80 loss : 0.813435 [  160/  182]\n",
      "Batch 90 loss : 0.313986 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266784\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538768\n",
      "\n",
      "Epcoh time : 4.0분 45.49769473075867 초\n",
      "Epoch 75 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 76\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313989 [    0/  182]\n",
      "Batch 10 loss : 0.314055 [   20/  182]\n",
      "Batch 20 loss : 0.314035 [   40/  182]\n",
      "Batch 30 loss : 1.312930 [   60/  182]\n",
      "Batch 40 loss : 0.813417 [   80/  182]\n",
      "Batch 50 loss : 0.314090 [  100/  182]\n",
      "Batch 60 loss : 0.313969 [  120/  182]\n",
      "Batch 70 loss : 0.313927 [  140/  182]\n",
      "Batch 80 loss : 0.813589 [  160/  182]\n",
      "Batch 90 loss : 0.813540 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266784\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538771\n",
      "\n",
      "Epcoh time : 4.0분 43.67086362838745 초\n",
      "Epoch 76 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 77\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 loss : 0.313972 [    0/  182]\n",
      "Batch 10 loss : 1.312994 [   20/  182]\n",
      "Batch 20 loss : 0.314079 [   40/  182]\n",
      "Batch 30 loss : 0.813329 [   60/  182]\n",
      "Batch 40 loss : 0.314237 [   80/  182]\n",
      "Batch 50 loss : 0.314127 [  100/  182]\n",
      "Batch 60 loss : 0.313992 [  120/  182]\n",
      "Batch 70 loss : 0.314032 [  140/  182]\n",
      "Batch 80 loss : 0.314021 [  160/  182]\n",
      "Batch 90 loss : 0.813540 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266785\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551262\n",
      "\n",
      "Epcoh time : 4.0분 43.30343532562256 초\n",
      "Epoch 77 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 78\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313961 [    0/  182]\n",
      "Batch 10 loss : 0.313956 [   20/  182]\n",
      "Batch 20 loss : 0.313939 [   40/  182]\n",
      "Batch 30 loss : 0.313926 [   60/  182]\n",
      "Batch 40 loss : 0.313972 [   80/  182]\n",
      "Batch 50 loss : 0.314039 [  100/  182]\n",
      "Batch 60 loss : 0.314102 [  120/  182]\n",
      "Batch 70 loss : 1.312549 [  140/  182]\n",
      "Batch 80 loss : 0.314142 [  160/  182]\n",
      "Batch 90 loss : 0.813547 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266786\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538773\n",
      "\n",
      "Epcoh time : 4.0분 46.575156688690186 초\n",
      "Epoch 78 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 79\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313958 [    0/  182]\n",
      "Batch 10 loss : 0.313954 [   20/  182]\n",
      "Batch 20 loss : 0.313974 [   40/  182]\n",
      "Batch 30 loss : 1.313199 [   60/  182]\n",
      "Batch 40 loss : 0.313986 [   80/  182]\n",
      "Batch 50 loss : 0.313992 [  100/  182]\n",
      "Batch 60 loss : 0.813286 [  120/  182]\n",
      "Batch 70 loss : 0.813006 [  140/  182]\n",
      "Batch 80 loss : 0.314187 [  160/  182]\n",
      "Batch 90 loss : 0.313920 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266795\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538786\n",
      "\n",
      "Epcoh time : 4.0분 43.92888593673706 초\n",
      "Epoch 79 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 80\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313915 [    0/  182]\n",
      "Batch 10 loss : 0.813679 [   20/  182]\n",
      "Batch 20 loss : 0.313904 [   40/  182]\n",
      "Batch 30 loss : 0.313928 [   60/  182]\n",
      "Batch 40 loss : 0.313939 [   80/  182]\n",
      "Batch 50 loss : 1.313347 [  100/  182]\n",
      "Batch 60 loss : 0.313942 [  120/  182]\n",
      "Batch 70 loss : 0.813591 [  140/  182]\n",
      "Batch 80 loss : 0.813527 [  160/  182]\n",
      "Batch 90 loss : 0.314115 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266783\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538763\n",
      "\n",
      "Epcoh time : 4.0분 44.98186111450195 초\n",
      "Epoch 80 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 81\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813317 [    0/  182]\n",
      "Batch 10 loss : 0.314412 [   20/  182]\n",
      "Batch 20 loss : 0.813283 [   40/  182]\n",
      "Batch 30 loss : 0.813378 [   60/  182]\n",
      "Batch 40 loss : 0.314085 [   80/  182]\n",
      "Batch 50 loss : 0.314082 [  100/  182]\n",
      "Batch 60 loss : 0.314159 [  120/  182]\n",
      "Batch 70 loss : 0.314078 [  140/  182]\n",
      "Batch 80 loss : 0.813498 [  160/  182]\n",
      "Batch 90 loss : 0.314007 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266785\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538767\n",
      "\n",
      "Epcoh time : 4.0분 46.076295375823975 초\n",
      "Epoch 81 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 82\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 1.312970 [    0/  182]\n",
      "Batch 10 loss : 0.314060 [   20/  182]\n",
      "Batch 20 loss : 0.314118 [   40/  182]\n",
      "Batch 30 loss : 0.813227 [   60/  182]\n",
      "Batch 40 loss : 0.314339 [   80/  182]\n",
      "Batch 50 loss : 0.314353 [  100/  182]\n",
      "Batch 60 loss : 0.314080 [  120/  182]\n",
      "Batch 70 loss : 0.313926 [  140/  182]\n",
      "Batch 80 loss : 0.813672 [  160/  182]\n",
      "Batch 90 loss : 0.813684 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266786\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551293\n",
      "\n",
      "Epcoh time : 4.0분 45.95547294616699 초\n",
      "Epoch 82 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 83\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313896 [    0/  182]\n",
      "Batch 10 loss : 0.313903 [   20/  182]\n",
      "Batch 20 loss : 0.313915 [   40/  182]\n",
      "Batch 30 loss : 0.813544 [   60/  182]\n",
      "Batch 40 loss : 0.314109 [   80/  182]\n",
      "Batch 50 loss : 0.314167 [  100/  182]\n",
      "Batch 60 loss : 0.314242 [  120/  182]\n",
      "Batch 70 loss : 0.314084 [  140/  182]\n",
      "Batch 80 loss : 0.313945 [  160/  182]\n",
      "Batch 90 loss : 0.313910 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266790\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551281\n",
      "\n",
      "Epcoh time : 4.0분 45.430742263793945 초\n",
      "Epoch 83 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 84\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313911 [    0/  182]\n",
      "Batch 10 loss : 0.813609 [   20/  182]\n",
      "Batch 20 loss : 1.313036 [   40/  182]\n",
      "Batch 30 loss : 0.314133 [   60/  182]\n",
      "Batch 40 loss : 0.813263 [   80/  182]\n",
      "Batch 50 loss : 0.314179 [  100/  182]\n",
      "Batch 60 loss : 0.314056 [  120/  182]\n",
      "Batch 70 loss : 0.313958 [  140/  182]\n",
      "Batch 80 loss : 0.813618 [  160/  182]\n",
      "Batch 90 loss : 0.313926 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266786\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551273\n",
      "\n",
      "Epcoh time : 4.0분 45.03283905982971 초\n",
      "Epoch 84 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 85\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813604 [    0/  182]\n",
      "Batch 10 loss : 0.313954 [   20/  182]\n",
      "Batch 20 loss : 0.313978 [   40/  182]\n",
      "Batch 30 loss : 0.313974 [   60/  182]\n",
      "Batch 40 loss : 0.313935 [   80/  182]\n",
      "Batch 50 loss : 0.813615 [  100/  182]\n",
      "Batch 60 loss : 0.813558 [  120/  182]\n",
      "Batch 70 loss : 0.813497 [  140/  182]\n",
      "Batch 80 loss : 0.314060 [  160/  182]\n",
      "Batch 90 loss : 0.813359 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266783\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538763\n",
      "\n",
      "Epcoh time : 4.0분 43.5345344543457 초\n",
      "Epoch 85 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 86\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314094 [    0/  182]\n",
      "Batch 10 loss : 0.313970 [   20/  182]\n",
      "Batch 20 loss : 0.813625 [   40/  182]\n",
      "Batch 30 loss : 0.313963 [   60/  182]\n",
      "Batch 40 loss : 1.312877 [   80/  182]\n",
      "Batch 50 loss : 0.314306 [  100/  182]\n",
      "Batch 60 loss : 0.813415 [  120/  182]\n",
      "Batch 70 loss : 0.313982 [  140/  182]\n",
      "Batch 80 loss : 0.813641 [  160/  182]\n",
      "Batch 90 loss : 1.313380 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266796\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538787\n",
      "\n",
      "Epcoh time : 4.0분 46.317410707473755 초\n",
      "Epoch 86 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 87\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313911 [    0/  182]\n",
      "Batch 10 loss : 0.313937 [   20/  182]\n",
      "Batch 20 loss : 0.313986 [   40/  182]\n",
      "Batch 30 loss : 0.314028 [   60/  182]\n",
      "Batch 40 loss : 0.813545 [   80/  182]\n",
      "Batch 50 loss : 0.813550 [  100/  182]\n",
      "Batch 60 loss : 0.813566 [  120/  182]\n",
      "Batch 70 loss : 0.813573 [  140/  182]\n",
      "Batch 80 loss : 0.313984 [  160/  182]\n",
      "Batch 90 loss : 1.312867 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266780\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551247\n",
      "\n",
      "Epcoh time : 4.0분 44.56844758987427 초\n",
      "Epoch 87 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 88\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813413 [    0/  182]\n",
      "Batch 10 loss : 1.312604 [   20/  182]\n",
      "Batch 20 loss : 0.813148 [   40/  182]\n",
      "Batch 30 loss : 0.813240 [   60/  182]\n",
      "Batch 40 loss : 0.314235 [   80/  182]\n",
      "Batch 50 loss : 0.314229 [  100/  182]\n",
      "Batch 60 loss : 0.813480 [  120/  182]\n",
      "Batch 70 loss : 0.313945 [  140/  182]\n",
      "Batch 80 loss : 0.313927 [  160/  182]\n",
      "Batch 90 loss : 0.813588 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266789\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538777\n",
      "\n",
      "Epcoh time : 4.0분 45.577152967453 초\n",
      "Epoch 88 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 89\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313939 [    0/  182]\n",
      "Batch 10 loss : 0.813508 [   20/  182]\n",
      "Batch 20 loss : 0.813357 [   40/  182]\n",
      "Batch 30 loss : 0.314165 [   60/  182]\n",
      "Batch 40 loss : 0.314006 [   80/  182]\n",
      "Batch 50 loss : 0.313958 [  100/  182]\n",
      "Batch 60 loss : 0.313929 [  120/  182]\n",
      "Batch 70 loss : 0.813588 [  140/  182]\n",
      "Batch 80 loss : 0.313980 [  160/  182]\n",
      "Batch 90 loss : 0.813441 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266784\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551249\n",
      "\n",
      "Epcoh time : 4.0분 43.06585431098938 초\n",
      "Epoch 89 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 90\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314033 [    0/  182]\n",
      "Batch 10 loss : 1.312718 [   20/  182]\n",
      "Batch 20 loss : 0.314140 [   40/  182]\n",
      "Batch 30 loss : 0.314026 [   60/  182]\n",
      "Batch 40 loss : 0.313933 [   80/  182]\n",
      "Batch 50 loss : 0.313938 [  100/  182]\n",
      "Batch 60 loss : 0.313979 [  120/  182]\n",
      "Batch 70 loss : 0.314028 [  140/  182]\n",
      "Batch 80 loss : 0.813395 [  160/  182]\n",
      "Batch 90 loss : 0.314058 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266784\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538763\n",
      "\n",
      "Epcoh time : 4.0분 44.82052659988403 초\n",
      "Epoch 90 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 91\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813401 [    0/  182]\n",
      "Batch 10 loss : 0.813417 [   20/  182]\n",
      "Batch 20 loss : 0.314089 [   40/  182]\n",
      "Batch 30 loss : 0.313998 [   60/  182]\n",
      "Batch 40 loss : 0.813492 [   80/  182]\n",
      "Batch 50 loss : 0.314094 [  100/  182]\n",
      "Batch 60 loss : 0.314174 [  120/  182]\n",
      "Batch 70 loss : 0.314055 [  140/  182]\n",
      "Batch 80 loss : 0.314047 [  160/  182]\n",
      "Batch 90 loss : 0.314019 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266782\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551251\n",
      "\n",
      "Epcoh time : 4.0분 44.522682666778564 초\n",
      "Epoch 91 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 92\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314013 [    0/  182]\n",
      "Batch 10 loss : 0.313966 [   20/  182]\n",
      "Batch 20 loss : 0.313946 [   40/  182]\n",
      "Batch 30 loss : 1.313226 [   60/  182]\n",
      "Batch 40 loss : 0.313925 [   80/  182]\n",
      "Batch 50 loss : 0.813629 [  100/  182]\n",
      "Batch 60 loss : 0.813560 [  120/  182]\n",
      "Batch 70 loss : 0.314002 [  140/  182]\n",
      "Batch 80 loss : 0.314105 [  160/  182]\n",
      "Batch 90 loss : 0.813190 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266777\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538768\n",
      "\n",
      "Epcoh time : 4.0분 43.98613262176514 초\n",
      "Epoch 92 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 93\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.314257 [    0/  182]\n",
      "Batch 10 loss : 0.314297 [   20/  182]\n",
      "Batch 20 loss : 0.314083 [   40/  182]\n",
      "Batch 30 loss : 0.313984 [   60/  182]\n",
      "Batch 40 loss : 0.813519 [   80/  182]\n",
      "Batch 50 loss : 0.314029 [  100/  182]\n",
      "Batch 60 loss : 0.314233 [  120/  182]\n",
      "Batch 70 loss : 0.314218 [  140/  182]\n",
      "Batch 80 loss : 0.813484 [  160/  182]\n",
      "Batch 90 loss : 0.813564 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266791\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538774\n",
      "\n",
      "Epcoh time : 4.0분 44.31477904319763 초\n",
      "Epoch 93 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 94\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813563 [    0/  182]\n",
      "Batch 10 loss : 0.813458 [   20/  182]\n",
      "Batch 20 loss : 0.314061 [   40/  182]\n",
      "Batch 30 loss : 0.813526 [   60/  182]\n",
      "Batch 40 loss : 0.813531 [   80/  182]\n",
      "Batch 50 loss : 0.313983 [  100/  182]\n",
      "Batch 60 loss : 0.813488 [  120/  182]\n",
      "Batch 70 loss : 1.312935 [  140/  182]\n",
      "Batch 80 loss : 0.314059 [  160/  182]\n",
      "Batch 90 loss : 0.813551 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266785\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538773\n",
      "\n",
      "Epcoh time : 4.0분 44.489898443222046 초\n",
      "Epoch 94 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 95\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313953 [    0/  182]\n",
      "Batch 10 loss : 0.313967 [   20/  182]\n",
      "Batch 20 loss : 0.314064 [   40/  182]\n",
      "Batch 30 loss : 0.314059 [   60/  182]\n",
      "Batch 40 loss : 0.313941 [   80/  182]\n",
      "Batch 50 loss : 0.813614 [  100/  182]\n",
      "Batch 60 loss : 0.313971 [  120/  182]\n",
      "Batch 70 loss : 0.813542 [  140/  182]\n",
      "Batch 80 loss : 0.813477 [  160/  182]\n",
      "Batch 90 loss : 0.313994 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266787\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538767\n",
      "\n",
      "Epcoh time : 4.0분 44.83189535140991 초\n",
      "Epoch 95 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 96\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813493 [    0/  182]\n",
      "Batch 10 loss : 0.813285 [   20/  182]\n",
      "Batch 20 loss : 0.813216 [   40/  182]\n",
      "Batch 30 loss : 0.813467 [   60/  182]\n",
      "Batch 40 loss : 0.313955 [   80/  182]\n",
      "Batch 50 loss : 0.313955 [  100/  182]\n",
      "Batch 60 loss : 0.313972 [  120/  182]\n",
      "Batch 70 loss : 0.813481 [  140/  182]\n",
      "Batch 80 loss : 0.313974 [  160/  182]\n",
      "Batch 90 loss : 1.313258 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266786\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538778\n",
      "\n",
      "Epcoh time : 4.0분 46.32666540145874 초\n",
      "Epoch 96 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 97\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313932 [    0/  182]\n",
      "Batch 10 loss : 1.313014 [   20/  182]\n",
      "Batch 20 loss : 0.314060 [   40/  182]\n",
      "Batch 30 loss : 0.813568 [   60/  182]\n",
      "Batch 40 loss : 0.813574 [   80/  182]\n",
      "Batch 50 loss : 0.813387 [  100/  182]\n",
      "Batch 60 loss : 0.314125 [  120/  182]\n",
      "Batch 70 loss : 0.813509 [  140/  182]\n",
      "Batch 80 loss : 0.313955 [  160/  182]\n",
      "Batch 90 loss : 0.813570 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266789\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538776\n",
      "\n",
      "Epcoh time : 4.0분 43.7891411781311 초\n",
      "Epoch 97 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 98\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.313940 [    0/  182]\n",
      "Batch 10 loss : 0.313963 [   20/  182]\n",
      "Batch 20 loss : 0.813470 [   40/  182]\n",
      "Batch 30 loss : 0.314445 [   60/  182]\n",
      "Batch 40 loss : 0.314357 [   80/  182]\n",
      "Batch 50 loss : 0.314041 [  100/  182]\n",
      "Batch 60 loss : 0.313927 [  120/  182]\n",
      "Batch 70 loss : 0.313903 [  140/  182]\n",
      "Batch 80 loss : 0.313896 [  160/  182]\n",
      "Batch 90 loss : 0.313913 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266792\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551278\n",
      "\n",
      "Epcoh time : 4.0분 45.24327802658081 초\n",
      "Epoch 98 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 99\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813626 [    0/  182]\n",
      "Batch 10 loss : 0.313944 [   20/  182]\n",
      "Batch 20 loss : 0.313954 [   40/  182]\n",
      "Batch 30 loss : 0.813606 [   60/  182]\n",
      "Batch 40 loss : 1.313243 [   80/  182]\n",
      "Batch 50 loss : 0.313966 [  100/  182]\n",
      "Batch 60 loss : 0.314000 [  120/  182]\n",
      "Batch 70 loss : 0.813470 [  140/  182]\n",
      "Batch 80 loss : 0.813421 [  160/  182]\n",
      "Batch 90 loss : 0.314229 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266780\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.551241\n",
      "\n",
      "Epcoh time : 4.0분 45.255126953125 초\n",
      "Epoch 99 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------------------\n",
      "데이터 사이즈 :  182\n",
      "Batch 0 loss : 0.813206 [    0/  182]\n",
      "Batch 10 loss : 0.314157 [   20/  182]\n",
      "Batch 20 loss : 0.314005 [   40/  182]\n",
      "Batch 30 loss : 0.313903 [   60/  182]\n",
      "Batch 40 loss : 0.313891 [   80/  182]\n",
      "Batch 50 loss : 0.813674 [  100/  182]\n",
      "Batch 60 loss : 1.313309 [  120/  182]\n",
      "Batch 70 loss : 0.313977 [  140/  182]\n",
      "Batch 80 loss : 0.314003 [  160/  182]\n",
      "Batch 90 loss : 0.813245 [  180/  182]\n",
      "Train\n",
      " Accuracy : 78.0%, Avg Loss : 0.266782\n",
      "\n",
      "Validation\n",
      " Accuracy : 77.2%, Avg Loss : 0.538767\n",
      "\n",
      "Epcoh time : 4.0분 42.835731744766235 초\n",
      "Epoch 100 End\n",
      "-------------------------------------------\n",
      "\n",
      "Epoch 걸린 시간 :  477.0  분 37.080766916275024  초\n"
     ]
    }
   ],
   "source": [
    "train_loss_info=[]\n",
    "train_acc_info=[]\n",
    "\n",
    "val_loss_info=[]\n",
    "val_acc_info=[]\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "for t in range(CFG['EPOCHS']):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------------------\")\n",
    "    start_epoch=time.time()\n",
    "    train_loss, train_acc=train_loop(train_dataloader, model, loss_fn, optimizer, scheduler)\n",
    "    train_loss_info.append(train_loss)\n",
    "    train_acc_info.append(train_acc)\n",
    "    \n",
    "    val_loss, val_acc=val_loop(validation_dataloader, model, loss_fn, scheduler)\n",
    "    val_loss_info.append(val_loss)\n",
    "    val_acc_info.append(val_acc)\n",
    "    \n",
    "    end_epoch=time.time()\n",
    "    print(f\"Epcoh time : {(end_epoch-start_epoch)//60}분 {(end_epoch-start_epoch)%60} 초\")\n",
    "    print(f\"Epoch {t+1} End\\n-------------------------------------------\")\n",
    "    print()\n",
    "    \n",
    "end=time.time()\n",
    "\n",
    "print(\"Epoch 걸린 시간 : \", (end-start)//60, \" 분\", (end-start)%60, \" 초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6107a97b",
   "metadata": {},
   "source": [
    "Plot Train Acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce6e60fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep=[i for i in range(1, CFG['EPOCHS']+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "89bcbd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ae83efc6a0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.title('train_loss_info')\n",
    "plt.plot(ep, train_loss_info, label='train')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fe882c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ae87c23a30>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.title('train_acc_info')\n",
    "plt.plot(ep, train_acc_info, label='train')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f42ee2",
   "metadata": {},
   "source": [
    "Plot val Acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f5112e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ae8e20c5b0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.title('val_loss_info')\n",
    "plt.plot(ep,val_loss_info, label='val')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ccfe89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ae87c3d790>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.title('val_acc_info')\n",
    "plt.plot(ep, val_acc_info, label='val')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b217f",
   "metadata": {},
   "source": [
    "# 13. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1f1d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='C:\\\\Users\\\\PC00\\\\Desktop\\\\ASD_data\\\\model\\\\T1\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c215b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, PATH+'model.pt') #전체 모델 저장\n",
    "torch.save(model.state_dict(), PATH+'model_state_dict.pt') #모델 객체의 state_dict 저장\n",
    "torch.save({\n",
    "    'model':model.state_dict(),\n",
    "    'optimizer':optimizer.state_dict()\n",
    "}, PATH+'all.tar') #여러 가지 값 저장, 학습 중 진행 상황 저장을 위해 epoch, loss 값 등 일반 scalar 값 저장 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672ba98b",
   "metadata": {},
   "source": [
    "# 14. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "799dca1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet18(\n",
       "  (conv1): Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=64, out_features=4, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=4, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "            (bn): BatchNorm3d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=64, out_features=4, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=4, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "            (bn): BatchNorm3d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=8, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "            (bn): BatchNorm3d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=8, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "            (bn): BatchNorm3d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "            (bn): BatchNorm3d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "            (bn): BatchNorm3d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=512, out_features=32, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=32, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "            (bn): BatchNorm3d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=512, out_features=32, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=32, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "            (bn): BatchNorm3d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (log_softmax): LogSoftmax(dim=None)\n",
       "  (softmax): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=torch.load(PATH+'model.pt') #전체 모델을 통째로 불러옴\n",
    "model.load_state_dict(torch.load(PATH+'model_state_dict.pt')) #state_dict를 불러 온 후, 모델에 저장\n",
    "\n",
    "checkpoint = torch.load(PATH + 'all.tar')   # dict 불러오기\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5bb31f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sensitivity\n",
    "#양성인 것중에 양성으로 판별\n",
    "\n",
    "#specificity\n",
    "#음성인 것중에 음성으로 판별\n",
    "\n",
    "def true_positive(p,t):\n",
    "    l=len(p)\n",
    "    cnt=0\n",
    "    for i in range(l):\n",
    "        if t[i]==1 and p[i]==1:\n",
    "            cnt+=1\n",
    "            \n",
    "    return cnt\n",
    "\n",
    "\n",
    "def true_negative(p,t):\n",
    "    l=len(p)\n",
    "    cnt=0\n",
    "    for i in range(l):\n",
    "        if t[i]==0 and p[i]==0:\n",
    "            cnt+=1\n",
    "    \n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b45ed7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader,model, loss_fn, test_asd, test_tc):\n",
    "    size=len(dataloader.dataset)\n",
    "    num_batches=len(dataloader)\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss, correct=0,0\n",
    "    \n",
    "    TP,TN=0,0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            X=Variable(X.to(device).float())\n",
    "            y=Variable(y.to(device).float())\n",
    "            \n",
    "            pred=model(X)\n",
    "            \n",
    "            #loss\n",
    "            test_loss+=loss_fn(pred, y).item()\n",
    "            #accuracy\n",
    "            correct+=(pred.argmax(1)==y.argmax(1)).type(torch.float).sum().item()\n",
    "            print(pred.argmax(1))\n",
    "            print(y.argmax(1))\n",
    "            print()\n",
    "            TP+=true_positive(pred.argmax(1), y.argmax(1))\n",
    "            TN+=true_negative(pred.argmax(1), y.argmax(1))\n",
    "    \n",
    "    FN=test_asd-TP\n",
    "    FP=test_tc-TN\n",
    "    test_loss/=num_batches\n",
    "    correct/=size\n",
    "    \n",
    "    print(f\"Test Error\\n Accuracy : {(100*correct):>0.1f}%, Avg Loss : {test_loss:>8f}\\n\")\n",
    "    print(f\"True Positive : {TP}\\nTrue Negative : {TN}\\nFalse Positive : {FP}\\nFalse Negative : {FN}\\n\")\n",
    "    return (TP/(TP+FN))*100, (TN/(FP+TN))*100, (TP/(TP+FP))*100, (TN/(FN+TN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "39c21bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1], device='cuda:0')\n",
      "tensor([1, 0], device='cuda:0')\n",
      "\n",
      "tensor([1, 1], device='cuda:0')\n",
      "tensor([1, 0], device='cuda:0')\n",
      "\n",
      "tensor([1, 1], device='cuda:0')\n",
      "tensor([1, 1], device='cuda:0')\n",
      "\n",
      "tensor([1, 1], device='cuda:0')\n",
      "tensor([0, 1], device='cuda:0')\n",
      "\n",
      "tensor([1, 1], device='cuda:0')\n",
      "tensor([0, 1], device='cuda:0')\n",
      "\n",
      "tensor([1, 1], device='cuda:0')\n",
      "tensor([0, 1], device='cuda:0')\n",
      "\n",
      "tensor([1, 1], device='cuda:0')\n",
      "tensor([0, 1], device='cuda:0')\n",
      "\n",
      "tensor([1, 1], device='cuda:0')\n",
      "tensor([0, 1], device='cuda:0')\n",
      "\n",
      "tensor([1, 1], device='cuda:0')\n",
      "tensor([0, 0], device='cuda:0')\n",
      "\n",
      "tensor([1, 1], device='cuda:0')\n",
      "tensor([1, 0], device='cuda:0')\n",
      "\n",
      "Test Error\n",
      " Accuracy : 50.0%, Avg Loss : 0.812772\n",
      "\n",
      "True Positive : 10\n",
      "True Negative : 0\n",
      "False Positive : 10\n",
      "False Negative : 0\n",
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m test_tc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      4\u001b[0m start\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 6\u001b[0m sensitivity, specificity, PPV, NPV\u001b[38;5;241m=\u001b[39m\u001b[43mtest_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_asd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_tc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m end\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest 걸린 시간 : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(end\u001b[38;5;241m-\u001b[39mstart)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 분 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(end\u001b[38;5;241m-\u001b[39mstart)\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 초\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[63], line 34\u001b[0m, in \u001b[0;36mtest_loop\u001b[1;34m(dataloader, model, loss_fn, test_asd, test_tc)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Error\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Accuracy : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39mcorrect)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>0.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, Avg Loss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>8f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue Positive : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTP\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTrue Negative : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFalse Positive : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFP\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFalse Negative : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (TP\u001b[38;5;241m/\u001b[39m(TP\u001b[38;5;241m+\u001b[39mFN))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m, (TN\u001b[38;5;241m/\u001b[39m(FP\u001b[38;5;241m+\u001b[39mTN))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m, (TP\u001b[38;5;241m/\u001b[39m(TP\u001b[38;5;241m+\u001b[39mFP))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m, (\u001b[43mTN\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFN\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mTN\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "test_asd=10\n",
    "test_tc=10\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "sensitivity, specificity, PPV, NPV=test_loop(test_dataloader ,model, loss_fn, test_asd, test_tc)\n",
    "\n",
    "end=time.time()\n",
    "\n",
    "print(f\"Test 걸린 시간 : {(end-start)//60} 분 {(end-start)%60:.1f} 초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1a4cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sensitivity : {sensitivity:.3f}%\")\n",
    "print(f\"Specificity : {specificity:.3f}%\")\n",
    "print(f\"PPV : {PPV:.3f}%\")\n",
    "print(f\"NPV : {NPV:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8d008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a048ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5635e84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
